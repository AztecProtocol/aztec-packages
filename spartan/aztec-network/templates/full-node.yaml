apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "aztec-network.fullname" . }}-full-node
  labels:
    {{- include "aztec-network.labels" . | nindent 4 }}
spec:
  serviceName: {{ include "aztec-network.fullname" . }}-full-node
  replicas: {{ .Values.fullNode.replicas }}
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      {{- include "aztec-network.selectorLabels" . | nindent 6 }}
      app: full-node
  {{- if not .Values.storage.localSsd }}
  volumeClaimTemplates:
    - metadata:
        name: full-node-data
        annotations:
          "helm.sh/resource-policy": {{ .Values.fullNode.storageRetentionPolicy | default "Delete" | quote }}
      spec:
        storageClassName: {{ .Values.fullNode.storageClass | default "standard" }}
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: {{ .Values.fullNode.storageSize }}
  {{- end }}
  template:
    metadata:
      labels:
        {{- include "aztec-network.selectorLabels" . | nindent 8 }}
        app: full-node
    spec:
      {{- if .Values.network.gke }}
      nodeSelector:
        local-ssd: "{{ .Values.storage.localSsd }}"
        node-type: network
      {{- end }}
      dnsPolicy: ClusterFirstWithHostNet
      {{- if .Values.network.public }}
      hostNetwork: true
      serviceAccountName: {{ include "aztec-network.fullname" . }}-node
      {{- include "aztec-network.publicAntiAffinity" . | nindent 6 }}
      {{- end }}
      initContainers:
        {{- include "aztec-network.combinedAllSetupContainer" . | nindent 8 }}
        {{- include "aztec-network.otelResourceSetupContainer" . | nindent 8 }}
        {{- include "aztec-network.combinedWaitAndConfigureContainer" . | nindent 8 }}

      containers:
        - name: full-node
          {{- include "aztec-network.image" . | nindent 10 }}
          command:
            - /bin/bash
            - -c
            - |
              source /shared/contracts/contracts.env
              source /shared/config/p2p-addresses
              source /shared/config/service-addresses
              env

              node --no-warnings /usr/src/yarn-project/aztec/dest/bin/index.js start --node --archiver --pxe
          startupProbe:
            httpGet:
              path: /status
              port: {{ .Values.fullNode.service.nodePort }}
            periodSeconds: {{ .Values.fullNode.startupProbe.periodSeconds }}
            failureThreshold: {{ .Values.fullNode.startupProbe.failureThreshold }}
          livenessProbe:
            httpGet:
              path: /status
              port: {{ .Values.fullNode.service.nodePort }}
            initialDelaySeconds: 30
            periodSeconds: 5
            timeoutSeconds: 30
            failureThreshold: 3
          volumeMounts:
            - name: config
              mountPath: /shared/config
            - name: full-node-data
              mountPath: {{ .Values.fullNode.dataDir }}
            - name: contracts-env
              mountPath: /shared/contracts/contracts.env
              subPath: contracts.env
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: K8S_POD_UID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.uid
            - name: K8S_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: OTEL_SERVICE_NAME
              value: full-node
            - name: K8S_NAMESPACE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NODE_OPTIONS
              value: "--max-old-space-size={{ .Values.fullNode.maxOldSpaceSize}}"
            - name: AZTEC_PORT
              value: "{{ .Values.fullNode.service.nodePort }}"
            - name: AZTEC_ADMIN_PORT
              value: "{{ .Values.fullNode.service.adminPort }}"
            - name: LOG_LEVEL
              value: "{{ .Values.fullNode.logLevel }}"
            - name: LOG_JSON
              value: "1"
            - name: P2P_ENABLED
              value: "{{ .Values.fullNode.p2p.enabled }}"
            - name: P2P_MAX_TX_POOL_SIZE
              value: "{{ .Values.network.mempoolLimitBytes }}"
            - name: P2P_GOSSIPSUB_FLOOD_PUBLISH
              value: "{{ .Values.fullNode.p2p.floodPublish }}"
            - name: COINBASE
              value: "{{ .Values.fullNode.coinbaseAddress }}"
            - name: VALIDATOR_DISABLED
              value: "true"
            - name: L1_CHAIN_ID
              value: "{{ .Values.ethereum.chainId }}"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name={{ .Release.Name }},service.namespace={{ .Release.Namespace }},service.version={{ .Chart.AppVersion }},environment={{ .Values.environment | default "production" }}
            - name: PROVER_REAL_PROOFS
              value: "{{ .Values.aztec.realProofs }}"
            - name: PXE_PROVER_ENABLED
              value: "{{ .Values.aztec.realProofs }}"
            - name: ETHEREUM_SLOT_DURATION
              value: "{{ .Values.ethereum.blockTime }}"
            - name: AZTEC_SLOT_DURATION
              value: "{{ .Values.aztec.slotDuration }}"
            - name: AZTEC_EPOCH_DURATION
              value: "{{ .Values.aztec.epochDuration }}"
            - name: AZTEC_PROOF_SUBMISSION_WINDOW
              value: "{{ .Values.aztec.proofSubmissionWindow }}"
            - name: ARCHIVER_POLLING_INTERVAL_MS
              value: {{ .Values.fullNode.archiverPollingInterval | quote }}
            - name: ARCHIVER_VIEM_POLLING_INTERVAL_MS
              value: {{ .Values.fullNode.archiverViemPollingInterval | quote }}
            - name: L1_READER_VIEM_POLLING_INTERVAL_MS
              value: {{ .Values.fullNode.archiverViemPollingInterval | quote }}
            - name: SEQ_VIEM_POLLING_INTERVAL_MS
              value: {{ .Values.fullNode.viemPollingInterval | quote }}
            - name: PEER_ID_PRIVATE_KEY
              value: "{{ .Values.fullNode.peerIdPrivateKey }}"
            - name: DATA_DIRECTORY
              value: "{{ .Values.fullNode.dataDir }}"
            - name: DATA_STORE_MAP_SIZE_KB
              value: "{{ .Values.storage.dataStoreMapSize }}"
            - name: WS_DB_MAP_SIZE_KB
              value: "{{ .Values.storage.worldStateMapSize }}"
            - name: USE_GCLOUD_LOGGING
              value: "{{ .Values.telemetry.useGcloudLogging }}"
            - name: OTEL_EXCLUDE_METRICS
              value: "{{ .Values.telemetry.excludeMetrics }}"
            - name: P2P_BOOTSTRAP_NODES_AS_FULL_PEERS
              value: "{{ .Values.network.p2pBootstrapNodesAsFullPeers }}"
            - name: TEST_ACCOUNTS
              value: "{{ .Values.aztec.testAccounts }}"
            - name: SPONSORED_FPC
              value: "{{ .Values.aztec.sponsoredFPC }}"
            - name: SYNC_SNAPSHOTS_URL
              value: "{{ .Values.snapshots.syncUrl }}"
            - name: SENTINEL_ENABLED
              value: "{{ .Values.fullNode.sentinelEnabled }}"
            - name: P2P_ARCHIVED_TX_LIMIT
              value: "{{ .Values.fullNode.p2p.archivedTxLimit }}"
            {{- if .Values.blobSink.enabled }}
            - name: BLOB_SINK_URL
              value: {{ include "aztec-network.blobSinkUrl" . }}
            {{- end }}
          ports:
            - containerPort: {{ .Values.fullNode.service.nodePort }}
            - containerPort: {{ .Values.fullNode.service.adminPort }}
            - containerPort: {{ .Values.fullNode.service.p2pPort }}
            - containerPort: {{ .Values.fullNode.service.p2pPort }}
              protocol: UDP
          resources:
            {{- toYaml .Values.fullNode.resources | nindent 12 }}
      volumes:
        - name: config
          emptyDir: {}
      {{- if .Values.storage.localSsd }}
        - name: full-node-data
          emptyDir: {}
      {{ else }}
        - name: full-node-data
          persistentVolumeClaim:
            claimName: full-node-data
      {{- end }}
        - name: scripts
          configMap:
            name: {{ include "aztec-network.fullname" . }}-scripts
            defaultMode: 0755
        - name: scripts-output
          emptyDir: {}
        - name: contracts-env
          emptyDir: {}
        - name: pxe-url
          emptyDir: {}
---
# Headless service for StatefulSet DNS entries
apiVersion: v1
kind: Service
metadata:
  name: {{ include "aztec-network.fullname" . }}-full-node
  labels:
    {{- include "aztec-network.labels" . | nindent 4 }}
    app: full-node
  annotations:
    {{- if hasKey .Values.fullNode "fixedStaticIpName" }}
    cloud.google.com/backend-config: '{"default": "{{ include "aztec-network.fullname" . }}-full-node-backend-config"}'
    {{- end }}
spec:
  # If this is a public network, we want to expose the fulls node as a LoadBalancer
  {{- if .Values.network.public }}
  type: LoadBalancer
  {{- else }}
  type: ClusterIP
  clusterIP: None
  {{- end }}
  selector:
    {{- include "aztec-network.selectorLabels" . | nindent 4 }}
    app: full-node
  ports:
    # External load balancers cannot handle mixed TCP/UDP ports, so we only expose the node port
    {{- if not .Values.network.public }}
    - port: {{ .Values.fullNode.service.p2pPort }}
      name: p2p-tpc
    - port: {{ .Values.fullNode.service.p2pPort }}
      name: p2p-udp
      protocol: UDP
    {{- end }}
    - port: {{ .Values.fullNode.service.nodePort }}
      name: node
---
# Internal service for accessing the admin port
apiVersion: v1
kind: Service
metadata:
  name: {{ include "aztec-network.fullname" . }}-full-node-admin
  labels:
    {{- include "aztec-network.labels" . | nindent 4 }}
    app: full-node
spec:
  type: ClusterIP
  selector:
    {{- include "aztec-network.selectorLabels" . | nindent 4 }}
    app: full-node
  # The admin port is restricted from public access thanks to terraform/gke-cluster/firewall.tf
  ports:
    - port: {{ .Values.fullNode.service.adminPort }}
      targetPort: {{ .Values.fullNode.service.adminPort }}
      name: admin
---
{{- if hasKey .Values.fullNode "fixedStaticIpName" }}
apiVersion: cloud.google.com/v1
kind: BackendConfig
metadata:
  name: {{ include "aztec-network.fullname" . }}-full-node-backend-config
  namespace: {{ .Release.Namespace }}
spec:
  healthCheck:
    checkIntervalSec: 15
    timeoutSec: 5
    healthyThreshold: 2
    unhealthyThreshold: 2
    type: HTTP
    requestPath: /status
    port: 8080
---
apiVersion: networking.gke.io/v1
kind: ManagedCertificate
metadata:
  name: {{ include "aztec-network.fullname" . }}-full-node-cert
spec:
  domains:
  # Note: A record must be added in this domain to point at  {{ .Values.fullNode.fixedStaticIpName }}
  - {{ .Values.fullNode.staticIpUrl }}
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: {{ include "aztec-network.fullname" . }}-full-node-ingress
  annotations:
    kubernetes.io/ingress.class: "gce"
    networking.gke.io/managed-certificates: {{ include "aztec-network.fullname" . }}-full-node-cert
    kubernetes.io/ingress.global-static-ip-name: {{ .Values.fullNode.fixedStaticIpName }}
    kubernetes.io/ingress.allow-http: "false"
    cloud.google.com/health-check-port: "8080"
    cloud.google.com/healthcheck-path: "/status"
spec:
  rules:
  - host: {{ .Values.fullNode.staticIpUrl }}
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: {{ include "aztec-network.fullname" . }}-full-node
            port:
              number: {{ .Values.fullNode.service.nodePort }}
{{- end }}
