opentelemetry-collector:
  resources:
    requests:
      memory: 2Gi
      cpu: "1"
  config:
    processors:
      memory_limiter:
        check_interval: 1s
        limit_percentage: 80
        spike_limit_percentage: 15

      filter/large_histograms:
        metrics:
          datapoint:
            - metric.type == METRIC_DATA_TYPE_HISTOGRAM and Len(explicit_bounds) > 20

      metricstransform:
        transforms:
          - include: 'system.cpu.utilization'
            match_type: strict
            action: combine
            new_name: 'system.cpu.utilization_combined'
            operations:
              - action: aggregate_labels
                label_set: [ system.cpu.state ]
                aggregation_type: mean

      transform/promote_resource_attributes:
        metric_statements:
          - context: datapoint
            statements:
            # see recommendations https://prometheus.io/docs/guides/opentelemetry/#promoting-resource-attributes
            - set(attributes["service.instance.id"], resource.attributes["service.instance.id"])
            - set(attributes["service.name"], resource.attributes["service.name"])
            - set(attributes["service.namespace"], resource.attributes["service.namespace"])
            - set(attributes["k8s.namespace.name"], resource.attributes["k8s.namespace.name"])
            - set(attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"])

    exporters:
      otlphttp/logs:
        endpoint: http://metrics-loki.metrics:3100/otlp
      otlp/tempo:
        endpoint: http://metrics-tempo.metrics:4317
        tls:
          insecure: true
      prometheus:
        endpoint: ${env:MY_POD_IP}:8889
        metric_expiration: 5m
        resource_to_telemetry_conversion:
          enabled: false # manually handled through transform
    service:
      pipelines:
        logs:
          receivers:
            - otlp
          processors:
            - memory_limiter
            - batch
          exporters:
            - otlphttp/logs
        traces:
          receivers:
            - otlp
          processors:
            - memory_limiter
            - batch
          exporters:
            - otlp/tempo
        metrics:
          receivers:
            - otlp
          processors:
            - memory_limiter
            - filter/large_histograms
            - metricstransform
            - transform/promote_resource_attributes
            - batch
          exporters:
            - prometheus
            # - debug

loki:
  deploymentMode: SingleBinary
  loki:
    auth_enabled: false
    commonConfig:
      replication_factor: 1
    storage:
      type: "filesystem"
    schemaConfig:
      configs:
        - from: "2024-01-01"
          store: tsdb
          index:
            prefix: loki_index_
            period: 24h
          object_store: filesystem # we're storing on filesystem so there's no real persistence here.
          schema: v13
    limits_config:
      ingestion_rate_mb: 4
      ingestion_burst_size_mb: 6
      max_global_streams_per_user: 5000
      max_query_series: 500
      max_query_lookback: 24h
      max_query_length: 1h
      max_query_parallelism: 8
      query_timeout: 3m
  singleBinary:
    replicas: 1
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 2000m
        memory: 2Gi
    persistence:
      size: 10Gi
  read:
    replicas: 0
  backend:
    replicas: 0
  write:
    replicas: 0

grafana:
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Loki
          type: loki
          url: http://metrics-loki.metrics:3100
        - name: Tempo
          type: tempo
          url: http://metrics-tempo.metrics:3100
        - name: Prometheus
          type: prometheus
          uid: spartan-metrics-prometheus
          isDefault: true
          url: http://metrics-prometheus-server.metrics:80
