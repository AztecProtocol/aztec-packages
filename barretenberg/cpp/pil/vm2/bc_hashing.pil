// Bytecode hashing.
include "precomputed.pil";
include "bc_decomposition.pil";
include "poseidon2_hash.pil";

// ###########
// Design idea
// ###########
//
// We have to fetch bytecode as packed field elements from bc_decomposition.pil
// For this, we need to introduce a selector in bc_decomposition.pil activated at
// pc == 0, 31, 63, .... for every bytecode.
// In bc_decomposition subtrace, we reconstruct the corresponding field element.
// Finally, we copy through a lookup/permutation based on the selector these field elements
// to here (bc_hashing.pil) and then proceed to hashing.

//   pc_index | bytecode_id | packed_field | incremental_hash |   output_hash      | latch |
// -----------+-------------+--------------+------------------+--------------------+--------
//      0     |      0      |     0xabc    |        len       | H(0xabc,len) = 0x2 |   0
//     31     |      0      |     0x123    |        0x2       | H(0x123,0x2) = 0x3 |   0
//     62     |      0      |     0x62d    |        0x3       | H(0x62d,0x3) = end |   1
//     0      |      1      |     0x4ab    |        len       | H(0x4ab,len) = 0x5 |   0
//     31     |      1      |     0x21f    |        0x5       | H(0x21f,0x5) = 0x6 |   0
//     62     |      2      |     0x12a    |        0x6       | H(0x12a,0x6) = 0x9 |   0
//     93     |      2      |     0x982    |        0x9       | H(0x982,0x9) = end |   1


// Notes
// Bytecode hashing is part of the infallible set of operations in the AVM. This means that while a prover has unconstrained access to certain inputs
// (e.g. latch) they need to be able to generate a valid bytecode hash in order to construct a satisfiable circuit.

// Therefore, a lot of the security assumptions we make here are dependent on the security assumption of the poseidon2 hash (i.e. it is intractable to
// find a meaningful collision etc).

// To use the example of the latch variable. A prover can place the latch in any row and that corresponding value will be used to test the correctness of the
// bytecode hash. We assume it is impossible, given a set of inputs (i0, i1, ..., iN) for the prover to find a subsequence within this input such that
// Hash(inputs) == Hash(subsequence).

namespace bc_hashing;

    pol commit sel;
    sel * (1 - sel) = 0;

    // Skippable
    #[skippable_if]
    sel = 0;

    // If the current row is not active, then there are no more active rows after that.
    // Note that sel cannot be activated in the first row as sel' is defined.
    // As a consequence, if a row is activated (sel == 1) somewhere in this sub-trace, then
    // the activated rows start from the second row and are contiguous.
    #[TRACE_CONTINUITY]
    (1 - precomputed.first_row) * (1 - sel) * sel' = 0;

    // Triggers the lookup to the address derivation subtrace, signifies the row that contains the final bytecode hash for this id
    // The sequencer can decide where to put this latch.
    pol commit latch;
    latch * (1 - latch) = 0;

    // latch == 1 ==> sel == 1
    #[SEL_TOGGLED_AT_LATCH]
    latch * (1 - sel) = 0;

    // Given both latch and first_row are boolean and that latch cannot be activated at first row (sel would have
    // to be activated which is impossible on first row.), LATCH_CONDITION is a boolean.
    pol LATCH_CONDITION = latch + precomputed.first_row;

    // The start of a new bytecode id and new set of hashing runs. Needs to be a committed column as it is used in the lookup
    pol commit start;
    start * (1 - start) = 0;

    // If the current row is a latch or the first row, the next row should be a start (if it's active)
    #[START_AFTER_LATCH]
    sel' * (start' - LATCH_CONDITION) = 0;

    // Used as part of the lookup into bytecode decomposition
    pol commit pc_index;
    // The PC increments by 31 each row as long as the row is not latched, in which case the next pc is zero
    #[PC_INCREMENTS]
    sel * (pc_index' - ((1 - LATCH_CONDITION) * (31 + pc_index))) = 0;

    pol commit bytecode_id;
    #[ID_CONSISTENCY]
    (1 - LATCH_CONDITION) * (bytecode_id' - bytecode_id) = 0;

    pol commit packed_field;
    #[GET_PACKED_FIELD]
    sel { pc_index, bytecode_id, packed_field }
    in
    bc_decomposition.sel_packed { bc_decomposition.pc, bc_decomposition.id, bc_decomposition.packed_field };

    // This tracks the incremental bytecode hash after the i-th input
    // The first incremental hash of each new bytecode_id is the length of the bytecode
    pol commit incremental_hash;

    // At the start of a new bytecode hash, the initial incremental hash has to be the length of the bytecode
    // Note the looked up PC = 0 (enforced by the PC_INCREMENTS relation), i.e. the initial incremental hash value == bytecode length
    #[IV_IS_LEN]
    start { pc_index, bytecode_id, incremental_hash }
    in
    bc_decomposition.sel_packed { bc_decomposition.pc, bc_decomposition.id, bc_decomposition.bytes_remaining };

    // Start Hashing, Poseidon2(packed_field, running_hash)
    pol commit output_hash;
    #[POSEIDON2_HASH]
    sel { packed_field, incremental_hash, output_hash }
    in poseidon2_hash.sel { poseidon2_hash.input_0, poseidon2_hash.input_1, poseidon2_hash.output };

    // The output hash has to be incremental_hash of the next row (unless it's latched)
    #[CHAIN_OUTPUT_TO_INCR]
    (1 - LATCH_CONDITION) * (incremental_hash' - output_hash) = 0;


    // #########################################################################################
    //                           Proof Sketch
    // #########################################################################################
    // We want to show that the output_hash at a row with latch == 1 correctly enforces that it
    // is the result of hashing the bytes of a given bytecode identified by bytecode_id.
    // Thanks to #[TRACE_CONTINUITY] and #[SEL_TOGGLED_AT_LATCH], we have the guarantee that
    // the rows above the final output_hash are activated. If they are activated, then
    // bytecode_id is maintained and pc_index decrements by 31 when we move to the top.
    // From #[START_AFTER_LATCH], we have the guarantee that we cannot meet a row with
    // latch == 1 before we meet start == 1 when we go up. This shows that bytecode_id,
    // pc_index, and incremental_hash evolution did not deviate from the happy path. When
    // we reach a row with start == 1 (we know we must reach one thanks to #[START_AFTER_LATCH]
    // enforces it on the second row.), then #[IV_IS_LEN] implies that pc_index and incremental_hash
    // are correctly initialized. Note also that thanks #[TRACE_CONTINUITY] and #[GET_PACKED_FIELD]
    // we retrieved packed_field at the right pc_index from bc_decomposition sub-trace.
    // We remark that before reaching another latch, a prover might add additional rows without
    // latch on top of the start or even add a row with start == 1. This does not have any security
    // impact as what matters is the guarantee to have a correct initialization at start. What is
    // more, having a row without latch on top of the start would mean that a Poseidon2 pre-image
    // for a small integer (bytes_remaining) must have been found.
