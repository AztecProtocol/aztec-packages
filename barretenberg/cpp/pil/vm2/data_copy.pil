include "memory.pil";
include "calldata.pil";
include "precomputed.pil";

// This trace handles CALLDATACOPY and RETURNDATACOPY
// It is memory aware and so is expected to call the memory subtrace directly
// Example: Lookup to execution trace
//  execution.sel_data_copy { 
//      clk, context_id,
//      context_id, parent_id
//      reg1, reg2, rop3
//      parent_calldata_size, parent_calldata_offset,
//      gadget_id
//  }
//  in
//  sel_data_copy {
//      clk, context_id,
//      src_context_id, dst_context_id,
//      data_copy_size, data_offset, write_address
//      data_size, data_addr,
//      operation_id
//  }

// Reading from calldata column 
// Calldata Trace
// +-----+-------+-------+------------+
// | sel | value | index | context_id |
// +-----+-------+-------+------------+
// |   1 |   100 |     1 |          1 |
// |   1 |   200 |     2 |          1 |
// |   1 |   300 |     3 |          1 |
// +-----+-------+-------+------------+
// Execution Trace                          (cd_size)  (cd_offset)
// +-----+-----+------------+-----------+------------+------------+
// | clk | sel | context_id | parent_id | register_1 | register_2 |
// +-----+-----+------------+-----------+------------+------------+
// |   1 |   1 |          1 |         0 |          3 |          0 |
// +-----+-----+------------+-----------+------------+------------+
// DataCopy Trace
// +-------------+------------+------------+-----------+------------------+----------+-------+------------+
// | sel_cd_copy | src_ctx_id | dst_ctx_id | copy_size | cd_copy_col_read | cd_index | value | write_addr |
// +-------------+------------+------------+-----------+------------------+----------+-------+------------+
// |           1 |          0 |          1 |         3 |                1 |        1 |   100 |          5 |
// |           1 |          0 |          1 |         2 |                1 |        2 |   200 |          6 |
// |           1 |          0 |          1 |         1 |                1 |        3 |   300 |          7 |
// +-------------+------------+------------+-----------+------------------+----------+-------+------------+


namespace data_copy;

    #[skippable_if]
    sel_rd_copy + sel_cd_copy = 0;

    // Selectors for calldata_copy and returndata_copy, mutually exclusive given a constrained gadget id
    pol commit sel_cd_copy;
    sel_cd_copy * (1 - sel_cd_copy) = 0;
    pol commit sel_rd_copy;
    sel_rd_copy * (1 - sel_rd_copy) = 0;

    // Gadget ID is supplied by the execution trace, if non-zero it can be 1 or 2 (instruction spec constrained)
    // depending on if the operation is calldatacopy or returndatacopy respectively
    pol commit operation_id;
    // Bitwise decomposition
    operation_id = sel_cd_copy + (2 ** 1) * sel_rd_copy;
    
    pol SEL = sel_rd_copy + sel_cd_copy;

    // TODO: Since we are memory aware, we need some kind of timestamp
    pol commit clk;

    // Constrained as inputs from execution trace
    pol commit src_context_id; // The context that is read from
    pol commit dst_context_id; // The context that is written to

    pol commit data_copy_size; // This is also the number of writes
    pol commit data_offset; // This is the offset within the data to start copying
    pol commit data_addr; // This is the address of the start of the data in parent/child
    pol commit data_size; // This is the size of the data in parent/child

    pol commit write_addr; // The dst addr, comes from lookup to main trace

    // Control flow management 
    // These selectors should be implied to be 1 if SEL = 1;
    pol commit sel_start;
    sel_start * (1 - sel_start) = 0;
    // An active row succeeding sel_end has to be a sel_start 
    #[END_AFTER_START]
    (sel_cd_copy' + sel_rd_copy') * sel_end * (sel_start' - 1) = 0;

    pol commit sel_end;
    sel_end * (1 - sel_end) = 0;
    pol WRITE_CNT_MINUS_ONE = data_copy_size - 1;
    pol commit next_write_count_inv;
    // sel_end = 1 IFF data_copy_size - 1 = 0;
    #[END_WRITE_CONDITION]
    SEL * (WRITE_CNT_MINUS_ONE * (sel_end * (1 - next_write_count_inv) + next_write_count_inv) - 1 + sel_end) = 0;

    // ===== Writing to dst_context_id =====
    // Data copy size decrements for each row until we end
    #[DECR_COPY_SIZE]
    SEL * (1 - sel_end) * (data_copy_size' - data_copy_size + 1) = 0;

    pol commit sel_mem_write;
    // Regardless of operation, we have to write
    // TODO check out of bound
    sel_mem_write = SEL;
    #[INCR_WRITE_ADDR]
    (1 - precomputed.first_row) * SEL * (1 - sel_end) * (write_addr' - write_addr - 1) = 0;
    #[MEM_WRITE]
    sel_mem_write { clk, write_addr, value, /*mem_tag=*/precomputed.zero/*(FF)*/, /*rw=*/sel_mem_write/*(write)*/, dst_context_id }
    in
    memory.sel { memory.clk, memory.address, memory.value, memory.tag, memory.rw, memory.space_id };

    // ===== Reading for nested call =====
    // === Helper ===
    // When calling calldatacopy, the src_context_id == parent_id
    pol commit is_top_level; // == 1 iff parent_id == 0
    is_top_level * (1 - is_top_level) = 0;
    pol commit parent_id_inv; // For zero-check of has_parent_ctx
    #[TOP_LEVEL_COND]
    SEL * (src_context_id * (is_top_level * (1 - parent_id_inv) + parent_id_inv) - 1 + is_top_level) = 0;

    // === Establishing the read_addr ===
    // (1) The initial Read Addr is data_addr + data_offset
    // (2) Subsequent read addrs are incremented by 1 unless this is a padding row
    // (3) Error handling if read_addr is OOB
    pol commit read_addr;  // The addr to start reading the data from
    SEL * sel_start * (read_addr - data_addr - data_offset) = 0;
    #[INCR_READ_ADDR]
    SEL * (1 - padding) * (1 - sel_end) * (read_addr' - read_addr - 1) = 0;

    // === Establishing number of reads ===
    // Number of reads: min(data_offset + data_copy_size, data_size)
    pol commit read_count;
    // TODO: @sel_start read_count = min(data_offset + data_copy_size, data_size)
    #[DECR_READ_COUNT]
    SEL * (1 - padding) * (read_count' - read_count + 1) = 0; // Decrement
    pol commit padding; // Padding = 1 if read_count = 0
    pol commit read_count_inv;
    #[PADDING_CONDITION]
    SEL * (read_count * (padding * (1 - read_count_inv) + read_count_inv) - 1 + padding) = 0;

    // Read from memory if we are not the top level call and not a padding row
    pol commit sel_mem_read; // If the current row is a memory op read
    sel_mem_read = SEL * (1 - is_top_level) * (1 - padding);

    // === Value Padding ===
    pol commit value;
    #[PAD_VALUE]
    SEL * padding * value = 0;

    #[MEM_READ]
    sel_mem_read { clk, read_addr, value, /*mem_tag=*/precomputed.zero/*FF*/, /*rw=*/precomputed.zero/*(read)*/, src_context_id }
    in
    memory.sel { memory.clk, memory.address, memory.value, memory.tag, memory.rw, memory.space_id };

    // ===== Reading for top level call =====
    // Reading from column
    // TODO: data size for top level column reads need to be constrained
    // After calldata hashing
    pol commit cd_copy_col_read;
    pol commit cd_index;
    #[CD_COPY_COLUMN]
    cd_copy_col_read = SEL * (1 - padding) * is_top_level * sel_cd_copy;
    sel_start * cd_copy_col_read * (cd_index - 1) = 0; // CD Index starts at 1
    #[INCR_CD_INDEX]
    SEL * (1 - sel_end) * cd_copy_col_read * (cd_index' - cd_index - 1) = 0; // Increment CD Index

    #[COL_READ]
    cd_copy_col_read { value, dst_context_id, cd_index }
    in
    calldata.sel { calldata.value, calldata.context_id, calldata.index };

