include "constants_gen.pil";
include "execution.pil";
include "ff_gt.pil";
include "gt.pil";
include "precomputed.pil";

namespace alu;

pol commit sel;

pol commit sel_err;

pol commit sel_op_add;
pol commit sel_op_sub;
pol commit sel_op_mul;
pol commit sel_op_div;
pol commit sel_op_fdiv;
pol commit sel_op_eq;
pol commit sel_op_lt;
pol commit sel_op_lte;
pol commit sel_op_not;
pol commit sel_op_shl;
pol commit sel_op_shr;
pol commit sel_op_truncate;
pol commit op_id;

pol commit ia;
pol commit ib;
pol commit ic;

pol commit ia_tag;
pol commit ib_tag;
pol commit ic_tag;

#[skippable_if]
sel = 0;

// carry flag
pol commit cf;

// Generic helper column
// Current use: EQ (inverse of a-b), DIV (remainder), and SHL (2**ib)
pol commit helper1;

// maximum bits the number can hold (i.e. 8 for a u8):
pol commit max_bits;
// maximum value the number can hold (i.e. 255 for a u8), we 'mod' by max_value + 1
pol commit max_value;
// we need a selector to conditionally lookup ff_gt when inputs a, b are fields:
pol commit sel_is_ff;
// we need a selector to conditionally perform u128 multiplication:
pol commit sel_is_u128;

pol IS_NOT_FF = 1 - sel_is_ff;
pol IS_NOT_U128 = 1 - sel_is_u128;

sel * (1 - sel) = 0;
cf * (1 - cf) = 0;
sel_is_ff * (1 - sel_is_ff) = 0;
sel_is_u128 * (1 - sel_is_u128) = 0;

// TODO: Should these errors be mutually exclusive? Both can occur for DIV, FDIV
#[ERR_CHECK]
sel_err = sel_tag_err + sel_div_0_err - sel_tag_err * sel_div_0_err;

// TODO: Consider to gate with (1 - sel_tag_err) for op_id. This might help us remove the (1 - sel_tag_err)
// in various operation relations below.
// Note that the op_ids below represent a binary decomposition (see constants_gen.pil):
#[OP_ID_CHECK]
op_id = sel_op_add * constants.AVM_EXEC_OP_ID_ALU_ADD
      + sel_op_sub * constants.AVM_EXEC_OP_ID_ALU_SUB
      + sel_op_mul * constants.AVM_EXEC_OP_ID_ALU_MUL
      + sel_op_div * constants.AVM_EXEC_OP_ID_ALU_DIV
      + sel_op_fdiv * constants.AVM_EXEC_OP_ID_ALU_FDIV
      + sel_op_eq * constants.AVM_EXEC_OP_ID_ALU_EQ
      + sel_op_lt * constants.AVM_EXEC_OP_ID_ALU_LT
      + sel_op_lte * constants.AVM_EXEC_OP_ID_ALU_LTE
      + sel_op_not * constants.AVM_EXEC_OP_ID_ALU_NOT
      + sel_op_shl * constants.AVM_EXEC_OP_ID_ALU_SHL
      + sel_op_shr * constants.AVM_EXEC_OP_ID_ALU_SHR
      + sel_op_truncate * constants.AVM_EXEC_OP_ID_ALU_TRUNCATE;

// Note: sel captures sel_op_truncate which is dispatched differently (see #[EXEC_DISPATCHING_CAST]). This is not an issue because
// sel_alu never selects an op_id = AVM_EXEC_OP_ID_ALU_TRUNCATE as prescribed by SUBTRACE_INFO_MAP.
#[REGISTER_TAG_VALUE]
execution.sel_execute_alu {
    execution.register[0], execution.mem_tag_reg[0], execution.register[1],
    execution.mem_tag_reg[1], execution.register[2], execution.mem_tag_reg[2], execution.subtrace_operation_id, execution.sel_opcode_error
} in sel {
    ia, ia_tag, ib, ib_tag, ic, ic_tag, op_id, sel_err
};

// MW Note: No need to range check values fit in their tag's max bits. Inputs a and b are reads (already checked), and c is checked in memory.
// Though in this circuit we could incorrectly set cf = false when we would overflow, the memory range check would catch that c is too large.

// IS_FF CHECKING

pol CHECK_TAG_FF = sel_op_div + sel_op_fdiv + sel_op_lt + sel_op_lte + sel_op_not + sel_shift_ops;
// We prove that sel_is_ff == 1 <==> ia_tag == MEM_TAG_FF
pol TAG_FF_DIFF = ia_tag - constants.MEM_TAG_FF;
pol commit tag_ff_diff_inv;
#[TAG_IS_FF]
CHECK_TAG_FF * (TAG_FF_DIFF * (sel_is_ff * (1 - tag_ff_diff_inv) + tag_ff_diff_inv) + sel_is_ff - 1) = 0;

// IS_U128 CHECKING

pol CHECK_TAG_U128 = sel_op_mul + sel_op_div;
// We prove that sel_is_u128 == 1 <==> ia_tag == MEM_TAG_U128
pol TAG_U128_DIFF = ia_tag - constants.MEM_TAG_U128;
pol commit tag_u128_diff_inv;
#[TAG_IS_U128]
CHECK_TAG_U128 * (TAG_U128_DIFF * (sel_is_u128 * (1 - tag_u128_diff_inv) + tag_u128_diff_inv) + sel_is_u128 - 1) = 0;

// TAG CHECKING

pol EXPECTED_C_TAG = (sel_op_add + sel_op_sub + sel_op_mul + sel_op_div + sel_op_truncate + sel_shift_ops) * ia_tag + (sel_op_eq + sel_op_lt + sel_op_lte) * constants.MEM_TAG_U1 + sel_op_fdiv * constants.MEM_TAG_FF;

// The tag of c is generated by the opcode and is never wrong.
// Gating with (1 - sel_tag_err) is necessary because when an error occurs, we have to set the tag to 0,
// which might not be equal to EXPECTED_C_TAG.
#[C_TAG_CHECK]
(1 - sel_err) * (EXPECTED_C_TAG - ic_tag) = 0;

pol commit sel_tag_err;
sel_tag_err * (1 - sel_tag_err) = 0;

// Tag errors currently have cases:
// 1. Input tagged as a field for NOT, DIV, or shift operations or non-field for FDIV operation
// 2. Mismatched tags for inputs a and b for all opcodes apart from TRUNC
// 1 is handled by checking FF_TAG_ERR in TAG_ERR_CHECK and 2 is handled in AB_TAGS_CHECK.
pol FF_TAG_ERR = (sel_op_div + sel_op_not + sel_shift_ops) * sel_is_ff + sel_op_fdiv * IS_NOT_FF;
pol commit sel_ab_tag_mismatch;
sel_ab_tag_mismatch * (1 - sel_ab_tag_mismatch) = 0;

// TODO(MW): It's technically possible to have BOTH cases be true if we perform a DIV or shift with FF ib and integer ia,
// so for now I take sel_ab_tag_mismatch * FF_TAG_ERR.
#[TAG_ERR_CHECK]
sel_tag_err = sel_ab_tag_mismatch + FF_TAG_ERR - sel_ab_tag_mismatch * FF_TAG_ERR;

// For NOT opcode, an error occurs if the tag of a is FF. In this case, tracegen will set
// b's tag as 0 which, while it would currently pass the checks below, is not a tag inequality we
// want to throw with sel_ab_tag_mismatch:
pol CHECK_AB_TAGS = 1 - sel_op_not * sel_is_ff - sel_op_truncate;
pol AB_TAGS_EQ = 1 - sel_ab_tag_mismatch;
pol commit ab_tags_diff_inv;
// Prove that sel_ab_tag_mismatch = 1 <==> we have a disallowed inequality between the tags:
#[AB_TAGS_CHECK]
CHECK_AB_TAGS * ( (ia_tag - ib_tag) * ( AB_TAGS_EQ * (1 - ab_tags_diff_inv) + ab_tags_diff_inv) - 1 + AB_TAGS_EQ ) = 0;

#[TAG_MAX_BITS_VALUE]
sel { ia_tag, max_bits, max_value } in precomputed.sel_tag_parameters { precomputed.clk, precomputed.tag_max_bits, precomputed.tag_max_value };

// BIT DECOMPOSITION

// We use the below to prove correct decomposition of limbs. Currently used by MUL, DIV, SHL, and SHR.
pol commit sel_decompose_a;
// #[OP_ID_CHECK] ensures selectors are mutually exclusive:
sel_decompose_a = sel_mul_div_u128 + sel_shift_ops * IS_NOT_FF;
// Currently, sel_decompose_b would just equal sel_mul_div_u128, so no need for another column.
pol commit a_lo, a_hi, b_lo, b_hi;
pol TWO_POW_64 = 2 ** 64;

// Reusing columns for decomposition (#[OP_ID_CHECK] ensures selectors are mutually exclusive):
pol DECOMPOSED_A = ((sel_mul_u128 + sel_shift_ops_no_overflow) * ia) + (sel_shift_ops - sel_shift_ops_no_overflow) * (ib - max_bits) + (sel_is_u128 * sel_op_div * (1 - sel_tag_err) * ic);
pol DECOMPOSED_B = ib;
// For MUL and DIV, we decompose into 64 bit limbs. For shifts, we have one limb of b bits and one limb of max_bits - b bits.
pol LIMB_SIZE = sel_mul_div_u128 * TWO_POW_64 + sel_shift_ops * two_pow_shift_lo_bits;

#[A_DECOMPOSITION]
sel_decompose_a * (DECOMPOSED_A - (a_lo + LIMB_SIZE * a_hi)) = 0;
#[B_DECOMPOSITION]
sel_mul_div_u128 * (DECOMPOSED_B - (b_lo + LIMB_SIZE * b_hi)) = 0;

// Note: the only current use for decomposition of b has 64 bit limbs, so no need for b_lo/hi_bits.
pol commit a_lo_bits, a_hi_bits;
// TODO: Once lookups support expression in tuple, we can inline constant_64 into the lookup.
// Note: only currently used for MUL/DIV u128, so gated by sel_mul_div_u128:
pol commit constant_64;
sel_mul_div_u128 * (64 - constant_64) = 0;

#[A_LO_BITS]
a_lo_bits - sel_mul_div_u128 * constant_64 - sel_shift_ops * shift_lo_bits = 0;

#[A_HI_BITS]
a_hi_bits - sel_mul_div_u128 * constant_64 - sel_shift_ops * SHIFT_HI_BITS = 0;

#[RANGE_CHECK_DECOMPOSITION_A_LO]
sel_decompose_a { a_lo, a_lo_bits } in range_check.sel { range_check.value, range_check.rng_chk_bits };

#[RANGE_CHECK_DECOMPOSITION_A_HI]
sel_decompose_a { a_hi, a_hi_bits } in range_check.sel { range_check.value, range_check.rng_chk_bits };

#[RANGE_CHECK_DECOMPOSITION_B_LO]
sel_mul_div_u128 { b_lo, constant_64 } in range_check.sel { range_check.value, range_check.rng_chk_bits };

#[RANGE_CHECK_DECOMPOSITION_B_HI]
sel_mul_div_u128 { b_hi, constant_64 } in range_check.sel { range_check.value, range_check.rng_chk_bits };


// ADD

sel_op_add * (1 - sel_op_add) = 0;

// SUB

sel_op_sub * (1 - sel_op_sub) = 0;

// ADD & SUB - Shared relation:

// For add, sel_op_add - sel_op_sub = 1 => check a + b - cf * carry = c
// For sub, sel_op_add - sel_op_sub = -1 => check a - b + cf * carry = c
#[ALU_ADD_SUB]
(sel_op_add + sel_op_sub) * (1 - sel_tag_err) * (ia - ic + (sel_op_add - sel_op_sub) * (ib - cf * (max_value + 1))) = 0;

// MUL

sel_op_mul * (1 - sel_op_mul) = 0;

pol commit c_hi;

// MUL - non u128

#[ALU_MUL_NON_U128]
sel_op_mul * IS_NOT_U128 * (1 - sel_tag_err) * (ia * ib - ic - (max_value + 1) * c_hi) = 0;

// MUL - u128

pol commit sel_mul_u128;
// sel_op_mul & sel_is_u128:
sel_mul_u128 = sel_is_u128 * sel_op_mul;

// Taken from vm1:
// We express a, b in 64-bit slices: a = a_l + a_h * 2^64
//                                   b = b_l + b_h * 2^64
// => a * b = a_l * b_l + (a_h * b_l + a_l * b_h) * 2^64 + (a_h * b_h) * 2^128 = c_hi_full * 2^128 + c
// => the 'top bits' are given by (c_hi_full - (a_h * b_h)) * 2^128
// We can show for a 64 bit c_hi = c_hi_full - (a_h * b_h) % 2^64 that:
// a_l * b_l + (a_h * b_l + a_l * b_h) * 2^64 = c_hi * 2^128 + c
// Equivalently (cf = 0 if a_h & b_h = 0):
// a * b_l + a_l * b_h * 2^64 = (cf * 2^64 + c_hi) * 2^128 + c
// => no need for a_h in final relation

#[ALU_MUL_U128]
sel_mul_u128 * (1 - sel_tag_err)
    * (
        ia * b_lo + a_lo * b_hi * TWO_POW_64            // a * b without the hi bits
        - ic                                            // c_lo
        - (max_value + 1) * (cf * TWO_POW_64 + c_hi)    // c_hi * 2^128 + (cf ? 2^192 : 0)
    ) = 0;

// No need to range_check c_hi for cases other than u128 because we know a and b's size from the tags and have looked
// up max_value. i.e. we cannot provide a malicious c, c_hi such that a + b - c_hi * 2^n = c passes for n < 128.
// No need to range_check c_lo = ic because the memory write will ensure ic <= max_value.
#[RANGE_CHECK_MUL_U128_C_HI]
sel_mul_u128 { c_hi, constant_64 } in range_check.sel { range_check.value, range_check.rng_chk_bits };

// DIV

sel_op_div * (1 - sel_op_div) = 0;

// We need to show that remainder < b (remainder stored in helper1)
// TODO(MW): Reuse #[INT_GT] by setting lt_ops_input_a = b, lt_ops_input_b = helper1, lt_ops_result_c = 1 (gated by div_0_err).
// The below only exists to gate this lookup for now:
pol commit sel_div_no_0_err;
sel_div_no_0_err = sel_op_div * (1 - sel_div_0_err);
#[GT_DIV_REMAINDER]
sel_div_no_0_err { ib, helper1, sel_op_div } in gt.sel { gt.input_a, gt.input_b, gt.res };

// DIV - u128

// Using this to switch on the range checks for decomposed u128 integers (#[OP_ID_CHECK] ensures selectors are mutually exclusive)
pol commit sel_mul_div_u128;
// sel_mul_u128 || (sel_is_u128 & sel_op_div)
sel_mul_div_u128 = sel_mul_u128 + (sel_is_u128 * sel_op_div);

// We share the logic from MUL, since here we also must show a product evaluates to a result:
//  c * b = a - remainder

// Taken from vm1:
// We express c, b in 64-bit slices: c = c_l + c_h * 2^64
//                                   b = b_l + b_h * 2^64
// => c * b = c_l * b_l + (c_h * b_l + c_l * b_h) * 2^64 + (c_h * b_h) * 2^128 = a - r
// => the 'top bits' of the LHS are given by (c_h * b_h) * 2^128
// For a happy path of 128 bit integer division (a / b = c), we cannot have both b and c > 64 bits
//  => c_h * b_h = 0 (see ALU_DIV_U128_CHECK)
//  => above is equivalent to:
// c_l * b_l + (c_h * b_l + c_l * b_h) * 2^64 = a - r
// c * b_l + c_l * b_h * 2^64 = a - r

// We shouldn't need to decompose a - r because the LHS is constrained to be < 192 bits, protecting against
// field underflows.

// Reuse columns b_lo, b_hi from MUL above to represent b (see B_DECOMPOSITION)
// Reuse columns a_lo, a_hi from MUL above to represent c (see A_DECOMPOSITION)

#[ALU_DIV_U128_CHECK]
sel_is_u128 * sel_op_div * (1 - sel_err) * a_hi * b_hi = 0;

#[ALU_DIV_U128]
sel_is_u128 * sel_op_div * (1 - sel_err) * (ic * b_lo + a_lo * b_hi * TWO_POW_64 - (ia - helper1)) = 0;

// FDIV

sel_op_fdiv * (1 - sel_op_fdiv) = 0;

// For FDIV, we reuse the same main relation for non-u128 DIV (ALU_FDIV_DIV_NON_U128) but constrain that there is no remainder, stored in helper1.
// => The relation shows that b * c = a for FF

// DIV & FDIV - shared ops
// #[OP_ID_CHECK] ensures selectors are mutually exclusive:
pol DIV_OPS = sel_op_div + sel_op_fdiv;

pol commit sel_div_0_err;
sel_div_0_err * (1 - sel_div_0_err) = 0;

// We prove that sel_div_0_err == 1 <==> DIV_OPS == 1 && b == 0:
//      sel_div_0_err == 1 <==> b == 0:         ib * (sel_div_0_err * (1 - b_inv) + b_inv) + sel_div_0_err - 1 = 0
//      sel_div_0_err == 1 => DIV_OPS == 1:  sel_div_0_err * ( sel_div_0_err - DIV_OPS ) = 0

// Proof:
// ==>:
// Assume sel_div_0_err == 1. Then #[DIV_0_ERR] becomes: DIV_OPS * ib + 1 - DIV_OPS = 0
// We note that DIV_OPS cannot be zero, otherwise we get 1 == 0.
// Since DIV_OPS is boolean, DIV_OPS == 1 and ib == 0
// <== :
// Assume DIV_OPS == 1 && ib == 0, we get for #[DIV_0_ERR]: sel_div_0_err - 1 + sel_div_0_err * (sel_div_0_err - 1) = 0
// sel_div_0_err being boolean the second additive term is zero and therefore sel_div_0_err - 1 == 0.
pol commit b_inv;
#[DIV_0_ERR]
DIV_OPS * (ib * (sel_div_0_err * (1 - b_inv) + b_inv) + sel_div_0_err - 1) + sel_div_0_err * (sel_div_0_err - DIV_OPS) = 0;

// DIV & FDIV - non u128

pol DIV_OPS_NON_U128 = (1 - sel_err) * (sel_op_fdiv + sel_op_div * IS_NOT_U128);

// Show a - remainder = b * c
// Note: Since a, b, c, and remainder are under 64 bits (or remainder == 0 for FF), we are protected against a - remainder underflowing,
// i.e. b * c (< 128bits) cannot equal underflowed a - remainder (> 253 bits)
#[ALU_FDIV_DIV_NON_U128]
DIV_OPS_NON_U128 * (ib * ic - (ia - sel_op_div * helper1)) = 0;

// EQ

sel_op_eq * (1 - sel_op_eq) = 0;
pol DIFF = ia - ib;

// Use helper1 to invert DIFF.
// ic is a boolean output and ic == 1 <==> a == b.
// Important: ic boolean constraint is enforced as part of write to memory due to ic_tag == U1 as enforced by #[C_TAG_CHECK].

// sel_op_eq == 1 => [ic == 1 <==> DIFF == 0]
#[EQ_OP_MAIN]
sel_op_eq * (1 - sel_tag_err) * (DIFF * (ic * (1 - helper1) + helper1) - 1 + ic) = 0;

// LT

sel_op_lt * (1 - sel_op_lt) = 0;

// LTE

sel_op_lte * (1 - sel_op_lte) = 0;

// LT & LTE - Shared relations:

pol commit sel_lt_ops;
sel_lt_ops = (1 - sel_tag_err) * (sel_op_lt + sel_op_lte);

pol commit sel_ff_lt_ops;
// sel_is_ff & sel_lt_ops:
sel_ff_lt_ops = sel_is_ff * sel_lt_ops;

pol commit sel_int_lt_ops;
// !sel_is_ff & sel_lt_ops:
sel_int_lt_ops = IS_NOT_FF * sel_lt_ops;

// To perform LT or LTE ops, we redirect to the GT gadget where we check lt_ops_input_a > lt_ops_input_b ? lt_ops_result_c:
//  For LT, we want to show that: a < b ? c, so we use GT with swapped inputs and check: b > a ? c
//      LT: lt_ops_input_a = ib, lt_ops_input_b = ia, lt_ops_result_c = ic
//  For LTE, we want to show that: a <= b ? c, so we use GT with values as they are input and negate the result: a > b ? !c
//      LTE: lt_ops_input_a = ia, lt_ops_input_b = ib, lt_ops_result_c = !ic
pol commit lt_ops_input_a, lt_ops_input_b, lt_ops_result_c;

#[LT_SWAP_INPUTS_A]
sel_op_lt * (lt_ops_input_a - ib) + sel_op_lte * (lt_ops_input_a - ia) = 0;

#[LT_SWAP_INPUTS_B]
sel_op_lt * (lt_ops_input_b - ia) + sel_op_lte * (lt_ops_input_b - ib) = 0;

#[LTE_NEGATE_RESULT_C]
sel_op_lt * (lt_ops_result_c - ic) + sel_op_lte * (1 - sel_tag_err) * ((1 - lt_ops_result_c) - ic) = 0;

#[FF_GT]
sel_ff_lt_ops { lt_ops_input_a, lt_ops_input_b, lt_ops_result_c }
in ff_gt.sel_gt { ff_gt.a, ff_gt.b, ff_gt.result };

#[INT_GT]
sel_int_lt_ops { lt_ops_input_a, lt_ops_input_b, lt_ops_result_c }
in gt.sel { gt.input_a, gt.input_b, gt.res };

// NOT
// Input is sent to ia, ia_tag and output is sent to ib, ib_tag.

sel_op_not * (1 - sel_op_not) = 0;

// Relation is: a + ~a = 2^k - 1, where k is the number of bits in a.
#[NOT_OP_MAIN]
sel_op_not * (1 - sel_tag_err) * (ia + ib - max_value) = 0;

// SHIFTS - Taken from vm1:
// Given (1) an input a, within the range [0, 2**128-1],
//       (2) a value s, the amount of bits to shift a by (stored in ib),
//       (3) and a memory tag, mem_tag that supports a maximum of t bits (stored in max_bits).
// Split input a into Big Endian hi and lo limbs, (we re-use the a_hi and a_lo columns we used for the MUL/DIV u128 operators)
// a_hi and a_lo, and the number of bits represented by the memory tag, t.
// If we are shifting by more than the bit length represented by the memory tag, the result is trivially zero.

// SHL

// === Steps when performing SHL
// (1) Prove the correct decomposition: a_hi * 2**(t-s) + a_lo = a ---> see #[A_DECOMPOSITION]
// (2) Range check a_hi < 2**s && a_lo < 2**(t-s)                  ---> see #[RANGE_CHECK_DECOMPOSITION_A_LO/HI]
// (3) Return a_lo * 2**s                                          ---> see #[ALU_SHL]
//
//  <-- s bits -->   | <-- (t-s) bits -->
// ------------------|-------------------
// |      a_hi       |      a_lo        | --> a
// --------------------------------------
//
// Use of helper1 for SHL:
//  We have: s (=ib), t (=max_bits), 2**(t-s) (=two_pow_shift_lo_bits), and 2**t (=max_value + 1)
//  We want: 2**s (=2**ib), ideally without another precomputed.power_of_2 lookup
//  Injecting 2**s (=helper1), we can check that 2**t == 2**(t-s) * 2**s:
#[SHL_TWO_POW_SHIFT]
sel_op_shl * sel_shift_ops_no_overflow * (1 - sel_tag_err) * (max_value + 1 - two_pow_shift_lo_bits * helper1) = 0;

#[ALU_SHL]
sel_op_shl * (1 - sel_tag_err) * (ic - sel_shift_ops_no_overflow * a_lo * helper1 ) = 0;

// SHR

// === Steps when performing SHR
// (1) Prove the correct decomposition: a_hi * 2**s + a_lo = a ---> see #[A_DECOMPOSITION]
// (2) Range check a_hi < 2**(t-s) && a_lo < 2**s              ---> see #[RANGE_CHECK_DECOMPOSITION_A_LO/HI]
// (3) Return a_hi                                             ---> see #[ALU_SHR]
//
//  <--(t-s) bits --> |   <-- s bits -->
// -------------------|-------------------
// |      a_hi        |       a_lo       | --> a
// ---------------------------------------

#[ALU_SHR]
sel_op_shr * (1 - sel_tag_err) * (ic - sel_shift_ops_no_overflow * a_hi) = 0;

// SHL & SHR - Shared relations:

pol commit sel_shift_ops;
// sel_op_shl || sel_op_shr:
sel_shift_ops = sel_op_shl + sel_op_shr;

pol commit sel_shift_ops_no_overflow;
// sel_shift_ops_no_overflow = 1 ==> sel_shift_ops = 1:
sel_shift_ops_no_overflow * (1 - sel_shift_ops) = 0;
// (sel_op_shl || sel_op_shr) & b < max_bits: see below* for constraining.
pol SHIFT_OVERFLOW = sel_shift_ops * (1 - sel_shift_ops_no_overflow);

// The bit size of the lo limb used by the shift:
pol commit shift_lo_bits;
pol commit two_pow_shift_lo_bits;

// *For SHL and SHR, when the shift (b) > max_bits we want SHIFT_OVERFLOW == 1 and c == 0:
//  SHL: a_lo_bits = max_bits - b -> will underflow
//  SHR: a_hi_bits = max_bits - b -> will underflow
//  so instead set a_lo = b - max_bits and shift_lo_bits = max_bits for both SHL and SHR (see DECOMPOSED_A) and reuse the range check
//  RANGE_CHECK_DECOMPOSITION_A_LO to prove that b > max_bits <==> SHIFT_OVERFLOW = 1 <==> c = 0.
// Note: sel_decompose_a is gated by IS_NOT_FF, so no gating for the FF tag error case is required below.

#[SHIFTS_LO_BITS]
shift_lo_bits
    - sel_shift_ops_no_overflow * (sel_op_shl * (max_bits - ib) + sel_op_shr * ib)
    - SHIFT_OVERFLOW * max_bits
    = 0;

// Set shift_hi_bits = max_bits in the overflow case, so RANGE_CHECK_DECOMPOSITION_A_HI passes. Since we set c == 0 in this case,
// we don't need to constrain that a_hi is within a certain limb size.
pol SHIFT_HI_BITS = max_bits - sel_shift_ops_no_overflow * shift_lo_bits;

#[SHIFTS_TWO_POW]
sel_shift_ops_no_overflow { shift_lo_bits, two_pow_shift_lo_bits } in precomputed.sel_range_8 { precomputed.clk, precomputed.power_of_2 };

// TRUNCATE (ALU part for opcodes CAST and SET)
// Input of truncation value is sent to ia, destination tag in ia_tag and output is computed as ic.
// We have one dispatching lookup from execution specific to CAST and another one for SET, as
// the layout for registers and operands strongly differ from other ALU opcodes.
// The truncation operates on the FF value of the input and we completely ignore its tag, therefore
// the tag of the input is in general not equal to ia_tag.

sel_op_truncate * (1 - sel_op_truncate) = 0;


// CAST DISPATCHING
// Serialization layout is: src_addr, dst_addr, dst_tag
// src_addr --> register[0], dst_addr --> register[1], dst_tag --> rop[2] (immediate and therefore not sent to register)
// Reminder: mem_tag_reg[0] is ignored and might be different than ia_tag.

// Inputs are:
// - register[0] (ia: value (as FF) to truncate)
// - rop[2] (ia_tag: destination tag)
// - subtrace_operation_id (op_id)

// Outputs are:
// - register[1] (ic: truncated value)
// - mem_tag_reg[1] (ic_tag: write tag == ia_tag as enforced by #[C_TAG_CHECK])
// Note that we enforce the output tag through this dispatching lookup by having ia_tag matching both mem_tag_reg[1] and rop[2].
#[EXEC_DISPATCHING_CAST]
execution.sel_execute_cast {
    execution.register[0], execution.rop[2], execution.subtrace_operation_id, execution.register[1], execution.mem_tag_reg[1], execution.sel_opcode_error
} in sel_op_truncate {
    ia, ia_tag, op_id, ic, ia_tag, /*sel_opcode_error=*/ precomputed.zero
};

// SET DISPATCHING
// Serialization layout is: dst_addr, dst_tag, value (immediate)
// dst_addr --> register[0], dst_tag --> rop[1], value --> rop[2] (dst_tag and value are
// immediate and therefore not sent to register)

// Inputs are:
// - rop[2] (ia: value (as FF) to truncate)
// - rop[1] (ia_tag: destination tag)
// - subtrace_operation_id (op_id)

// Outputs are:
// - register[0] (ic: truncated value)
// - mem_tag_reg[0] (ic_tag: write tag == ia_tag as enforced by #[C_TAG_CHECK])
// Note that we enforce the output tag through this dispatching lookup by having ia_tag matching both mem_tag_reg[0] and rop[1].
#[EXEC_DISPATCHING_SET]
execution.sel_execute_set {
    execution.rop[2], execution.rop[1], execution.subtrace_operation_id, execution.register[0], execution.mem_tag_reg[0], execution.sel_opcode_error
} in sel_op_truncate {
    ia, ia_tag, op_id, ic, ic_tag, /*sel_opcode_error=*/ precomputed.zero
};

// 3 cases for truncation:
// - No truncation required (ia <= max_value)
// - truncation for ia >= 2^128
// - truncation for ia < 2^128
pol commit sel_trunc_trivial;
pol commit sel_trunc_gte_128;
pol commit sel_trunc_lt_128;

// If ia >= 2^128 and dst_tag != FF, and a malicious sequencer would toggle sel_trunc_trivial, this would
// fail in the range check pertaining to the memory write. If he would toggle sel_tunc_lt_128, this would
// fail in the decomposition of ia == lo_128 in #[TRUNC_LO_128_DECOMPOSITION], because the range checks
// on mid and ic (memory write) ensures a correct 128-bit decomposition of ia.
// If ia < 2^128 and ia > max_value, and a malicious sequencer would toggle sel_trunc_trivial,
// then the memory write would fail because ia == ic > max_value.

// Boolean
sel_trunc_trivial * (1 - sel_trunc_trivial) = 0;
sel_trunc_gte_128 * (1 - sel_trunc_gte_128) = 0;
sel_trunc_lt_128 * (1 - sel_trunc_lt_128) = 0;

// Truncation separation case
// Mutually exclusive due to sel_op_truncate being boolean
pol commit sel_trunc_non_trivial; // TODO: Aliases this once lookups support aliases for selectors.

#[SEL_TRUNC_NON_TRIVIAL]
sel_trunc_non_trivial = sel_trunc_gte_128 + sel_trunc_lt_128;

#[SEL_TRUNCATE]
sel_op_truncate = sel_trunc_non_trivial + sel_trunc_trivial;

// Trivial case: (the constraint that ic <= max_value is enforced by the memory write)
#[TRUNC_TRIVIAL_CASE]
sel_trunc_trivial * (ia - ic) = 0;

// NOTE: reusing a_lo and a_hi columns from MUL in TRUNC:
// For truncate, a_lo = 128-bit low limb of ia and a_hi = 128-bit high limb of ia.
pol commit mid;

#[LARGE_TRUNC_CANONICAL_DEC]
sel_trunc_gte_128 { ia, a_lo, a_hi }
in
ff_gt.sel_dec { ff_gt.a, ff_gt.a_lo, ff_gt.a_hi };

#[SMALL_TRUNC_VAL_IS_LO]
sel_trunc_lt_128 * (a_lo - ia) = 0;

// a_lo = ic + mid * 2^ia_tag_bits, where 2^ia_tag_bits is max_value + 1.
#[TRUNC_LO_128_DECOMPOSITION]
sel_trunc_non_trivial * (ic + mid * (max_value + 1) - a_lo) = 0;

// TODO: Once lookups support expression in tuple, we can inline mid_bits into the lookup.
pol commit mid_bits;
#[TRUNC_MID_BITS]
mid_bits = sel_trunc_non_trivial * (128 - max_bits);

// Note that for ia_tag == U128 the range check is trivial (0, 0) but
// is supported by our range_check gadget.
// No need to range_check ic because the memory write will ensure ic <= max_value.
#[RANGE_CHECK_TRUNC_MID]
sel_trunc_non_trivial { mid, mid_bits } in range_check.sel { range_check.value, range_check.rng_chk_bits };
