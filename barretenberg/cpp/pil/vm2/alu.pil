include "constants_gen.pil";
include "execution.pil";
include "ff_gt.pil";
include "gt.pil";
include "precomputed.pil";

namespace alu;

pol commit sel;

pol commit sel_err;

pol commit sel_op_add;
pol commit sel_op_sub;
pol commit sel_op_mul;
pol commit sel_op_div;
pol commit sel_op_eq;
pol commit sel_op_lt;
pol commit sel_op_lte;
pol commit sel_op_not;
pol commit sel_op_shl;
pol commit sel_op_shr;
pol commit sel_op_truncate;
pol commit op_id;

pol commit ia;
pol commit ib;
pol commit ic;

pol commit ia_tag;
pol commit ib_tag;
pol commit ic_tag;

#[skippable_if]
sel = 0;

// carry flag
pol commit cf;

// Generic helper column
// Current use: EQ (inverse of a-b) & DIV (remainder)
pol commit helper1;

// maximum bits the number can hold (i.e. 8 for a u8):
pol commit max_bits;
// maximum value the number can hold (i.e. 255 for a u8), we 'mod' by max_value + 1
pol commit max_value;
// we need a selector to conditionally lookup ff_gt when inputs a, b are fields:
pol commit sel_is_ff;
// we need a selector to conditionally perform u128 multiplication:
pol commit sel_is_u128;

pol IS_NOT_FF = 1 - sel_is_ff;
pol IS_NOT_U128 = 1 - sel_is_u128;

sel * (1 - sel) = 0;
cf * (1 - cf) = 0;
sel_is_ff * (1 - sel_is_ff) = 0;
sel_is_u128 * (1 - sel_is_u128) = 0;

// TODO: Should these errors be mutually exclusive? Both can occur for DIV, FDIV
#[ERR_CHECK]
sel_err = sel_tag_err + sel_div_0_err - sel_tag_err * sel_div_0_err;

// TODO: Consider to gate with (1 - sel_tag_err) for op_id. This might help us remove the (1 - sel_tag_err)
// in various operation relations below.
// Note that the op_ids below represent a binary decomposition (see constants_gen.pil):
#[OP_ID_CHECK]
op_id = sel_op_add * constants.AVM_EXEC_OP_ID_ALU_ADD
      + sel_op_sub * constants.AVM_EXEC_OP_ID_ALU_SUB
      + sel_op_mul * constants.AVM_EXEC_OP_ID_ALU_MUL
      + sel_op_div * constants.AVM_EXEC_OP_ID_ALU_DIV
      + sel_op_eq * constants.AVM_EXEC_OP_ID_ALU_EQ
      + sel_op_lt * constants.AVM_EXEC_OP_ID_ALU_LT
      + sel_op_lte * constants.AVM_EXEC_OP_ID_ALU_LTE
      + sel_op_not * constants.AVM_EXEC_OP_ID_ALU_NOT
      + sel_op_shl * constants.AVM_EXEC_OP_ID_ALU_SHL
      + sel_op_shr * constants.AVM_EXEC_OP_ID_ALU_SHR
      + sel_op_truncate * constants.AVM_EXEC_OP_ID_ALU_TRUNCATE;

// Note: sel captures sel_op_truncate which is dispatched differently (see #[EXEC_DISPATCHING_CAST]). This is not an issue because
// sel_alu never selects an op_id = AVM_EXEC_OP_ID_ALU_TRUNCATE as prescribed by SUBTRACE_INFO_MAP.
#[REGISTER_TAG_VALUE]
execution.sel_execute_alu {
    execution.register[0], execution.mem_tag_reg[0], execution.register[1],
    execution.mem_tag_reg[1], execution.register[2], execution.mem_tag_reg[2], execution.subtrace_operation_id, execution.sel_opcode_error
} in sel {
    ia, ia_tag, ib, ib_tag, ic, ic_tag, op_id, sel_err
};

// MW Note: No need to range check values fit in their tag's max bits. Inputs a and b are reads (already checked), and c is checked in memory.
// Though in this circuit we could incorrectly set cf = false when we would overflow, the memory range check would catch that c is too large.

// IS_FF CHECKING

pol CHECK_TAG_FF = sel_op_div + sel_op_lt + sel_op_lte + sel_op_not;
// We prove that sel_is_ff == 1 <==> ia_tag == MEM_TAG_FF
pol TAG_FF_DIFF = ia_tag - constants.MEM_TAG_FF;
pol commit tag_ff_diff_inv;
#[TAG_IS_FF]
CHECK_TAG_FF * (TAG_FF_DIFF * (sel_is_ff * (1 - tag_ff_diff_inv) + tag_ff_diff_inv) + sel_is_ff - 1) = 0;

// IS_U128 CHECKING

pol CHECK_TAG_U128 = sel_op_mul + sel_op_div;
// We prove that sel_is_u128 == 1 <==> ia_tag == MEM_TAG_U128
pol TAG_U128_DIFF = ia_tag - constants.MEM_TAG_U128;
pol commit tag_u128_diff_inv;
#[TAG_IS_U128]
CHECK_TAG_U128 * (TAG_U128_DIFF * (sel_is_u128 * (1 - tag_u128_diff_inv) + tag_u128_diff_inv) + sel_is_u128 - 1) = 0;

// TAG CHECKING

// Will become e.g. sel_op_add * ia_tag + (comparison ops) * MEM_TAG_U1 + ....
pol EXPECTED_C_TAG = (sel_op_add + sel_op_sub + sel_op_mul + sel_op_div + sel_op_truncate + sel_op_shr + sel_op_shl) * ia_tag + (sel_op_eq + sel_op_lt + sel_op_lte) * constants.MEM_TAG_U1;

// The tag of c is generated by the opcode and is never wrong.
// Gating with (1 - sel_tag_err) is necessary because when an error occurs, we have to set the tag to 0,
// which might not be equal to EXPECTED_C_TAG.
#[C_TAG_CHECK]
(1 - sel_tag_err) * (EXPECTED_C_TAG - ic_tag) = 0;

pol commit sel_tag_err;
sel_tag_err * (1 - sel_tag_err) = 0;

// Tag errors currently have cases:
// 1. Input tagged as a field for NOT or DIV operations
// 2. Mismatched tags for inputs a and b for all opcodes apart from TRUNC
// 1 is handled by checking FF_TAG_ERR in TAG_ERR_CHECK and 2 is handled in AB_TAGS_CHECK.
pol FF_TAG_ERR = (sel_op_div + sel_op_not) * sel_is_ff;
pol commit sel_ab_tag_mismatch;
sel_ab_tag_mismatch * (1 - sel_ab_tag_mismatch) = 0;

// TODO(MW): It's technically possible to have BOTH cases be true if we perform a DIV with FF ib and integer ia,
// so for now I take sel_ab_tag_mismatch * FF_TAG_ERR.
#[TAG_ERR_CHECK]
sel_tag_err = sel_ab_tag_mismatch + FF_TAG_ERR - sel_ab_tag_mismatch * FF_TAG_ERR;

// For NOT opcode, an error occurs if the tag of a is FF. In this case, tracegen will set
// b's tag as 0 which, while it would currently pass the checks below, is not a tag inequality we
// want to throw with sel_ab_tag_mismatch:
pol CHECK_AB_TAGS = 1 - sel_op_not * sel_is_ff - sel_op_truncate - sel_op_shr - sel_op_shl; // note: shifts are temporary, they should be subject to AB checks
pol AB_TAGS_EQ = 1 - sel_ab_tag_mismatch;
pol commit ab_tags_diff_inv;
// Prove that sel_ab_tag_mismatch = 1 <==> we have a disallowed inequality between the tags:
#[AB_TAGS_CHECK]
CHECK_AB_TAGS * ( (ia_tag - ib_tag) * ( AB_TAGS_EQ * (1 - ab_tags_diff_inv) + ab_tags_diff_inv) - 1 + AB_TAGS_EQ ) = 0;

#[TAG_MAX_BITS_VALUE]
sel { ia_tag, max_bits, max_value } in precomputed.sel_tag_parameters { precomputed.clk, precomputed.tag_max_bits, precomputed.tag_max_value };


// ADD

sel_op_add * (1 - sel_op_add) = 0;

// SUB

sel_op_sub * (1 - sel_op_sub) = 0;

// ADD & SUB - Shared relation:

// For add, sel_op_add - sel_op_sub = 1 => check a + b - cf * carry = c
// For sub, sel_op_add - sel_op_sub = -1 => check a - b + cf * carry = c
#[ALU_ADD_SUB]
(sel_op_add + sel_op_sub) * (1 - sel_tag_err) * (ia - ic + (sel_op_add - sel_op_sub) * (ib - cf * (max_value + 1))) = 0;

// MUL

sel_op_mul * (1 - sel_op_mul) = 0;

pol commit c_hi;

// MUL - non u128

#[ALU_MUL_NON_U128]
sel_op_mul * IS_NOT_U128 * (1 - sel_tag_err) * (ia * ib - ic - (max_value + 1) * c_hi) = 0;

// MUL - u128

pol commit sel_mul_u128;
// sel_op_mul & sel_is_u128:
sel_mul_u128 = sel_is_u128 * sel_op_mul;

// Taken from vm1:
// We express a, b in 64-bit slices: a = a_l + a_h * 2^64
//                                   b = b_l + b_h * 2^64
// => a * b = a_l * b_l + (a_h * b_l + a_l * b_h) * 2^64 + (a_h * b_h) * 2^128 = c_hi_full * 2^128 + c
// => the 'top bits' are given by (c_hi_full - (a_h * b_h)) * 2^128
// We can show for a 64 bit c_hi = c_hi_full - (a_h * b_h) % 2^64 that:
// a_l * b_l + (a_h * b_l + a_l * b_h) * 2^64 = c_hi * 2^128 + c
// Equivalently (cf = 0 if a_h & b_h = 0):
// a * b_l + a_l * b_h * 2^64 = (cf * 2^64 + c_hi) * 2^128 + c
// => no need for a_h in final relation

pol commit a_lo;
pol commit a_hi;
pol commit b_lo;
pol commit b_hi;
pol TWO_POW_64 = 2 ** 64;

// Reusing columns for decomposition (#[OP_ID_CHECK] ensures selectors are mutually exclusive):
pol DECOMPOSED_A = (sel_mul_u128 * ia) + (sel_is_u128 * sel_op_div * (1 - sel_tag_err) * ic);
pol DECOMPOSED_B = ib;

#[A_DECOMPOSITION]
sel_mul_div_u128 * (DECOMPOSED_A - (a_lo + TWO_POW_64 * a_hi)) = 0;
#[B_DECOMPOSITION]
sel_mul_div_u128 * (DECOMPOSED_B - (b_lo + TWO_POW_64 * b_hi)) = 0;

#[ALU_MUL_U128]
sel_mul_u128 * (1 - sel_tag_err)
    * (
        ia * b_lo + a_lo * b_hi * TWO_POW_64            // a * b without the hi bits
        - ic                                            // c_lo
        - (max_value + 1) * (cf * TWO_POW_64 + c_hi)    // c_hi * 2^128 + (cf ? 2^192 : 0)
    ) = 0;

// TODO: Once lookups support expression in tuple, we can inline constant_64 into the lookup.
// Note: only used for MUL/DIV u128, so gated by sel_mul_div_u128
pol commit constant_64;
sel_mul_div_u128 * (64 - constant_64) = 0;

#[RANGE_CHECK_MUL_U128_A_LO]
sel_mul_div_u128 { a_lo, constant_64 } in range_check.sel { range_check.value, range_check.rng_chk_bits };

#[RANGE_CHECK_MUL_U128_A_HI]
sel_mul_div_u128 { a_hi, constant_64 } in range_check.sel { range_check.value, range_check.rng_chk_bits };

#[RANGE_CHECK_MUL_U128_B_LO]
sel_mul_div_u128 { b_lo, constant_64 } in range_check.sel { range_check.value, range_check.rng_chk_bits };

#[RANGE_CHECK_MUL_U128_B_HI]
sel_mul_div_u128 { b_hi, constant_64 } in range_check.sel { range_check.value, range_check.rng_chk_bits };

// No need to range_check c_hi for cases other than u128 because we know a and b's size from the tags and have looked
// up max_value. i.e. we cannot provide a malicious c, c_hi such that a + b - c_hi * 2^n = c passes for n < 128.
// No need to range_check c_lo = ic because the memory write will ensure ic <= max_value.
#[RANGE_CHECK_MUL_U128_C_HI]
sel_mul_u128 { c_hi, constant_64 } in range_check.sel { range_check.value, range_check.rng_chk_bits };

// DIV

sel_op_div * (1 - sel_op_div) = 0;

pol commit sel_div_0_err;
sel_div_0_err * (1 - sel_div_0_err) = 0;

// We prove that sel_div_0_err == 1 <==> sel_op_div == 1 && b == 0:
//      sel_div_0_err == 1 <==> b == 0:         ib * (sel_div_0_err * (1 - b_inv) + b_inv) + sel_div_0_err - 1 = 0
//      sel_div_0_err == 1 => sel_op_div == 1:  sel_div_0_err * ( sel_div_0_err - sel_op_div ) = 0

// Proof:
// ==>:
// Assume sel_div_0_err == 1. Then #[DIV_0_ERR] becomes: sel_op_div * ib + 1 - sel_op_div = 0
// We note that sel_op_div cannot be zero, otherwise we get 1 == 0.
// Since sel_op_div is boolean, sel_op_div == 1 and ib == 0
// <== :
// Assume sel_op_div == 1 && ib == 0, we get for #[DIV_0_ERR]: sel_div_0_err - 1 + sel_div_0_err * (sel_div_0_err - 1) = 0
// sel_div_0_err being boolean the second additive term is zero and therefore sel_div_0_err - 1 == 0.
pol commit b_inv;
#[DIV_0_ERR]
sel_op_div * (ib * (sel_div_0_err * (1 - b_inv) + b_inv) + sel_div_0_err - 1) + sel_div_0_err * ( sel_div_0_err - sel_op_div ) = 0;

// We need to show that remainder < b (remainder stored in helper1)
// TODO(MW): Reuse #[INT_GT] by setting lt_ops_input_a = b, lt_ops_input_b = helper1, lt_ops_result_c = 1 (gated by div_0_err).
// The below only exists to gate this lookup for now:
pol commit sel_div_no_0_err;
sel_div_no_0_err = sel_op_div * (1 - sel_div_0_err);
#[GT_DIV_REMAINDER]
sel_div_no_0_err { ib, helper1, sel_op_div } in gt.sel { gt.input_a, gt.input_b, gt.res };

// DIV - non u128

// Show a - remainder = b * c
// Note: Since a, b, c, and remainder are under 64 bits, we are protected against a - remainder underflowing,
// i.e. b * c (< 128bits) cannot equal underflowed a - remainder (> 253 bits)
#[ALU_DIV_NON_U128]
sel_op_div * IS_NOT_U128 * (1 - sel_err) * (ib * ic - (ia - helper1)) = 0;

// DIV - u128

// Using this to switch on the range checks for decomposed u128 integers (#[OP_ID_CHECK] ensures selectors are mutually exclusive)
pol commit sel_mul_div_u128;
// sel_mul_u128 || (sel_is_u128 & sel_op_div)
sel_mul_div_u128 = sel_mul_u128 + (sel_is_u128 * sel_op_div);

// We share the logic from MUL, since here we also must show a product evaluates to a result:
//  c * b = a - remainder

// Taken from vm1:
// We express c, b in 64-bit slices: c = c_l + c_h * 2^64
//                                   b = b_l + b_h * 2^64
// => c * b = c_l * b_l + (c_h * b_l + c_l * b_h) * 2^64 + (c_h * b_h) * 2^128 = a - r
// => the 'top bits' of the LHS are given by (c_h * b_h) * 2^128
// For a happy path of 128 bit integer division (a / b = c), we cannot have both b and c > 64 bits
//  => c_h * b_h = 0 (see ALU_DIV_U128_CHECK)
//  => above is equivalent to:
// c_l * b_l + (c_h * b_l + c_l * b_h) * 2^64 = a - r
// c * b_l + c_l * b_h * 2^64 = a - r

// We shouldn't need to decompose a - r because the LHS is constrained to be < 192 bits, protecting against
// field underflows.

// Reuse columns b_lo, b_hi from MUL above to represent b (see B_DECOMPOSITION)
// Reuse columns a_lo, a_hi from MUL above to represent c (see A_DECOMPOSITION)

#[ALU_DIV_U128_CHECK]
sel_is_u128 * sel_op_div * (1 - sel_err) * a_hi * b_hi = 0;

#[ALU_DIV_U128]
sel_is_u128 * sel_op_div * (1 - sel_err) * (ic * b_lo + a_lo * b_hi * TWO_POW_64 - (ia - helper1)) = 0;

// EQ

sel_op_eq * (1 - sel_op_eq) = 0;
pol DIFF = ia - ib;

// Use helper1 to invert DIFF.
// ic is a boolean output and ic == 1 <==> a == b.
// Important: ic boolean constraint is enforced as part of write to memory due to ic_tag == U1 as enforced by #[C_TAG_CHECK].

// sel_op_eq == 1 => [ic == 1 <==> DIFF == 0]
#[EQ_OP_MAIN]
sel_op_eq * (1 - sel_tag_err) * (DIFF * (ic * (1 - helper1) + helper1) - 1 + ic) = 0;

// LT

sel_op_lt * (1 - sel_op_lt) = 0;

// LTE

sel_op_lte * (1 - sel_op_lte) = 0;

// LT & LTE - Shared relations:

pol commit sel_lt_ops;
sel_lt_ops = (1 - sel_tag_err) * (sel_op_lt + sel_op_lte);

pol commit sel_ff_lt_ops;
// sel_is_ff & sel_lt_ops:
sel_ff_lt_ops = sel_is_ff * sel_lt_ops;

pol commit sel_int_lt_ops;
// !sel_is_ff & sel_lt_ops:
sel_int_lt_ops = IS_NOT_FF * sel_lt_ops;

// To perform LT or LTE ops, we redirect to the GT gadget where we check lt_ops_input_a > lt_ops_input_b ? lt_ops_result_c:
//  For LT, we want to show that: a < b ? c, so we use GT with swapped inputs and check: b > a ? c
//      LT: lt_ops_input_a = ib, lt_ops_input_b = ia, lt_ops_result_c = ic
//  For LTE, we want to show that: a <= b ? c, so we use GT with values as they are input and negate the result: a > b ? !c
//      LTE: lt_ops_input_a = ia, lt_ops_input_b = ib, lt_ops_result_c = !ic
pol commit lt_ops_input_a, lt_ops_input_b, lt_ops_result_c;

#[LT_SWAP_INPUTS_A]
sel_op_lt * (lt_ops_input_a - ib) + sel_op_lte * (lt_ops_input_a - ia) = 0;

#[LT_SWAP_INPUTS_B]
sel_op_lt * (lt_ops_input_b - ia) + sel_op_lte * (lt_ops_input_b - ib) = 0;

#[LTE_NEGATE_RESULT_C]
sel_op_lt * (lt_ops_result_c - ic) + sel_op_lte * (1 - sel_tag_err) * ((1 - lt_ops_result_c) - ic) = 0;

#[FF_GT]
sel_ff_lt_ops { lt_ops_input_a, lt_ops_input_b, lt_ops_result_c }
in ff_gt.sel_gt { ff_gt.a, ff_gt.b, ff_gt.result };

#[INT_GT]
sel_int_lt_ops { lt_ops_input_a, lt_ops_input_b, lt_ops_result_c }
in gt.sel { gt.input_a, gt.input_b, gt.res };

// NOT
// Input is sent to ia, ia_tag and output is sent to ib, ib_tag.

sel_op_not * (1 - sel_op_not) = 0;

// Relation is: a + ~a = 2^k - 1, where k is the number of bits in a.
#[NOT_OP_MAIN]
sel_op_not * (1 - sel_tag_err) * (ia + ib - max_value) = 0;

// TRUNCATE (ALU part for opcodes CAST and SET)
// Input of truncation value is sent to ia, destination tag in ia_tag and output is computed as ic.
// We have one dispatching lookup from execution specific to CAST and another one for SET, as
// the layout for registers and operands strongly differ from other ALU opcodes.
// The truncation operates on the FF value of the input and we completely ignore its tag, therefore
// the tag of the input is in general not equal to ia_tag.

sel_op_truncate * (1 - sel_op_truncate) = 0;


// CAST DISPATCHING
// Serialization layout is: src_addr, dst_addr, dst_tag
// src_addr --> register[0], dst_addr --> register[1], dst_tag --> rop[2] (immediate and therefore not sent to register)
// Reminder: mem_tag_reg[0] is ignored and might be different than ia_tag.

// Inputs are:
// - register[0] (ia: value (as FF) to truncate)
// - rop[2] (ia_tag: destination tag)
// - subtrace_operation_id (op_id)

// Outputs are:
// - register[1] (ic: truncated value)
// - mem_tag_reg[1] (ic_tag: write tag == ia_tag as enforced by #[C_TAG_CHECK])
// Note that we enforce the output tag through this dispatching lookup by having ia_tag matching both mem_tag_reg[1] and rop[2].
#[EXEC_DISPATCHING_CAST]
execution.sel_execute_cast {
    execution.register[0], execution.rop[2], execution.subtrace_operation_id, execution.register[1], execution.mem_tag_reg[1]
} in sel_op_truncate {
    ia, ia_tag, op_id, ic, ia_tag
};

// SET DISPATCHING
// Serialization layout is: dst_addr, dst_tag, value (immediate)
// dst_addr --> register[0], dst_tag --> rop[1], value --> rop[2] (dst_tag and value are
// immediate and therefore not sent to register)

// Inputs are:
// - rop[2] (ia: value (as FF) to truncate)
// - rop[1] (ia_tag: destination tag)
// - subtrace_operation_id (op_id)

// Outputs are:
// - register[0] (ic: truncated value)
// - mem_tag_reg[0] (ic_tag: write tag == ia_tag as enforced by #[C_TAG_CHECK])
// Note that we enforce the output tag through this dispatching lookup by having ia_tag matching both mem_tag_reg[0] and rop[1].
#[EXEC_DISPATCHING_SET]
execution.sel_execute_set {
    execution.rop[2], execution.rop[1], execution.subtrace_operation_id, execution.register[0], execution.mem_tag_reg[0]
} in sel_op_truncate {
    ia, ia_tag, op_id, ic, ic_tag
};

// 3 cases for truncation:
// - No truncation required (ia <= max_value)
// - truncation for ia >= 2^128
// - truncation for ia < 2^128
pol commit sel_trunc_trivial;
pol commit sel_trunc_gte_128;
pol commit sel_trunc_lt_128;

// If ia >= 2^128 and dst_tag != FF, and a malicious sequencer would toggle sel_trunc_trivial, this would
// fail in the range check pertaining to the memory write. If he would toggle sel_tunc_lt_128, this would
// fail in the decomposition of ia == lo_128 in #[TRUNC_LO_128_DECOMPOSITION], because the range checks
// on mid and ic (memory write) ensures a correct 128-bit decomposition of ia.
// If ia < 2^128 and ia > max_value, and a malicious sequencer would toggle sel_trunc_trivial,
// then the memory write would fail because ia == ic > max_value.

// Boolean
sel_trunc_trivial * (1 - sel_trunc_trivial) = 0;
sel_trunc_gte_128 * (1 - sel_trunc_gte_128) = 0;
sel_trunc_lt_128 * (1 - sel_trunc_lt_128) = 0;

// Truncation separation case
// Mutually exclusive due to sel_op_truncate being boolean
pol commit sel_trunc_non_trivial; // TODO: Aliases this once lookups support aliases for selectors.

#[SEL_TRUNC_NON_TRIVIAL]
sel_trunc_non_trivial = sel_trunc_gte_128 + sel_trunc_lt_128;

#[SEL_TRUNCATE]
sel_op_truncate = sel_trunc_non_trivial + sel_trunc_trivial;

// Trivial case: (the constraint that ic <= max_value is enforced by the memory write)
#[TRUNC_TRIVIAL_CASE]
sel_trunc_trivial * (ia - ic) = 0;

// NOTE: reusing a_lo and a_hi columns from MUL in TRUNC:
// For truncate, a_lo = 128-bit low limb of ia and a_hi = 128-bit high limb of ia.
pol commit mid;

#[LARGE_TRUNC_CANONICAL_DEC]
sel_trunc_gte_128 { ia, a_lo, a_hi }
in
ff_gt.sel_dec { ff_gt.a, ff_gt.a_lo, ff_gt.a_hi };

#[SMALL_TRUNC_VAL_IS_LO]
sel_trunc_lt_128 * (a_lo - ia) = 0;

// a_lo = ic + mid * 2^ia_tag_bits, where 2^ia_tag_bits is max_value + 1.
#[TRUNC_LO_128_DECOMPOSITION]
sel_trunc_non_trivial * (ic + mid * (max_value + 1) - a_lo) = 0;

// TODO: Once lookups support expression in tuple, we can inline mid_bits into the lookup.
pol commit mid_bits;
#[TRUNC_MID_BITS]
mid_bits = sel_trunc_non_trivial * (128 - max_bits);

// Note that for ia_tag == U128 the range check is trivial (0, 0) but
// is supported by our range_check gadget.
// No need to range_check ic because the memory write will ensure ic <= max_value.
#[RANGE_CHECK_TRUNC_MID]
sel_trunc_non_trivial { mid, mid_bits } in range_check.sel { range_check.value, range_check.rng_chk_bits };
