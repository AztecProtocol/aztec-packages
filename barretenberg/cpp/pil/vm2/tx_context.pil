namespace tx;


    // This the same sel as in tx
    #[skippable_if]
    sel = 0;

    // Previous Tree State
    pol commit prev_note_hash_tree_root;
    pol commit prev_note_hash_tree_size;
    pol commit prev_num_note_hashes_emitted;

    pol commit prev_nullifier_tree_root;
    pol commit prev_nullifier_tree_size;
    pol commit prev_num_nullifiers_emitted;

    pol commit prev_public_data_tree_root;
    pol commit prev_public_data_tree_size;

    pol commit prev_written_public_data_slots_tree_root;
    pol commit prev_written_public_data_slots_tree_size;

    // L1 to L2 tree doesn't evolve during execution of the AVM
    pol commit l1_l2_tree_root;

    pol commit prev_retrieved_bytecodes_tree_root;
    pol commit prev_retrieved_bytecodes_tree_size;

    // TODO: Constrain first row read from PI
    pol commit prev_l2_gas_used;
    pol commit prev_da_gas_used;

    // Gas Info
    pol commit l2_gas_limit;
    pol commit da_gas_limit;

    // Prev side effect states
    pol commit prev_num_unencrypted_logs;
    pol commit prev_num_l2_to_l1_messages;

    // ==== READ START/END STATE FROM PI ====
    // TODO: Consider making this mechanism generic - might not be worth it in a short trace like the tx one.

    // Read start/end state of the note hash tree from PI
    pol commit note_hash_pi_offset;
    start_tx * (constants.AVM_PUBLIC_INPUTS_START_TREE_SNAPSHOTS_NOTE_HASH_TREE_ROW_IDX - note_hash_pi_offset) = 0;
    is_cleanup * (constants.AVM_PUBLIC_INPUTS_END_TREE_SNAPSHOTS_NOTE_HASH_TREE_ROW_IDX - note_hash_pi_offset) = 0;

    pol commit should_read_note_hash_tree;
    should_read_note_hash_tree = start_tx + is_cleanup;

    #[PUBLIC_INPUTS_NOTE_HASH_TREE]
    should_read_note_hash_tree {
        note_hash_pi_offset,
        prev_note_hash_tree_root,
        prev_note_hash_tree_size
    } in public_inputs.sel {
        precomputed.clk,
        public_inputs.cols[0],
        public_inputs.cols[1]
    };

    start_tx * prev_num_note_hashes_emitted = 0;

    // Read start/end state of the nullifier tree from PI
    pol commit nullifier_pi_offset;
    start_tx * (constants.AVM_PUBLIC_INPUTS_START_TREE_SNAPSHOTS_NULLIFIER_TREE_ROW_IDX - nullifier_pi_offset) = 0;
    is_cleanup * (constants.AVM_PUBLIC_INPUTS_END_TREE_SNAPSHOTS_NULLIFIER_TREE_ROW_IDX - nullifier_pi_offset) = 0;

    pol commit should_read_nullifier_tree;
    should_read_nullifier_tree = start_tx + is_cleanup;

    #[PUBLIC_INPUTS_NULLIFIER_TREE]
    should_read_nullifier_tree {
        nullifier_pi_offset,
        prev_nullifier_tree_root,
        prev_nullifier_tree_size
    } in public_inputs.sel {
        precomputed.clk,
        public_inputs.cols[0],
        public_inputs.cols[1]
    };

    start_tx * prev_num_nullifiers_emitted = 0;

    // Read start/end state of the public data tree from PI
    pol commit public_data_pi_offset;
    start_tx * (constants.AVM_PUBLIC_INPUTS_START_TREE_SNAPSHOTS_PUBLIC_DATA_TREE_ROW_IDX - public_data_pi_offset) = 0;
    is_cleanup * (constants.AVM_PUBLIC_INPUTS_END_TREE_SNAPSHOTS_PUBLIC_DATA_TREE_ROW_IDX - public_data_pi_offset) = 0;

    pol commit should_read_public_data_tree;
    should_read_public_data_tree = start_tx + is_cleanup;

    #[PUBLIC_INPUTS_PUBLIC_DATA_TREE]
    should_read_public_data_tree {
        public_data_pi_offset,
        prev_public_data_tree_root,
        prev_public_data_tree_size
    } in public_inputs.sel {
        precomputed.clk,
        public_inputs.cols[0],
        public_inputs.cols[1]
    };

    // Ensure the written public data slots tree starts with the expected state on every tx execution.
    start_tx * (constants.AVM_WRITTEN_PUBLIC_DATA_SLOTS_TREE_INITIAL_ROOT - prev_written_public_data_slots_tree_root) = 0;
    start_tx * (constants.AVM_WRITTEN_PUBLIC_DATA_SLOTS_TREE_INITIAL_SIZE - prev_written_public_data_slots_tree_size) = 0;

    // Read the state of the l1 to l2 message tree from PI
    pol commit l1_l2_pi_offset;
    start_tx * (constants.AVM_PUBLIC_INPUTS_START_TREE_SNAPSHOTS_L1_TO_L2_MESSAGE_TREE_ROW_IDX - l1_l2_pi_offset) = 0;
    is_cleanup * (constants.AVM_PUBLIC_INPUTS_END_TREE_SNAPSHOTS_L1_TO_L2_MESSAGE_TREE_ROW_IDX - l1_l2_pi_offset) = 0;

    pol commit should_read_l1_l2_tree;
    should_read_l1_l2_tree = start_tx + is_cleanup;

    #[PUBLIC_INPUTS_L1_L2_TREE]
    should_read_l1_l2_tree {
        l1_l2_pi_offset,
        l1_l2_tree_root
    } in public_inputs.sel {
        precomputed.clk,
        public_inputs.cols[0]
    };

    // Ensure the retrieved bytecodes tree starts with the expected state on every tx execution.
    start_tx * (constants.AVM_RETRIEVED_BYTECODES_TREE_INITIAL_ROOT - prev_retrieved_bytecodes_tree_root) = 0;
    start_tx * (constants.AVM_RETRIEVED_BYTECODES_TREE_INITIAL_SIZE - prev_retrieved_bytecodes_tree_size) = 0;

    // Read start/end state of gas used from PI
    pol commit gas_used_pi_offset;
    start_tx * (constants.AVM_PUBLIC_INPUTS_START_GAS_USED_ROW_IDX - gas_used_pi_offset) = 0;
    is_cleanup * (constants.AVM_PUBLIC_INPUTS_END_GAS_USED_ROW_IDX - gas_used_pi_offset) = 0;

    pol commit should_read_gas_used;
    should_read_gas_used = start_tx + is_cleanup;

    #[PUBLIC_INPUTS_GAS_USED]
    should_read_gas_used {
        gas_used_pi_offset,
        prev_da_gas_used,
        prev_l2_gas_used
    } in public_inputs.sel {
        precomputed.clk,
        public_inputs.cols[0],
        public_inputs.cols[1]
    };

    // Read gas limit and teardown gas limit from PI

    pol commit gas_limit_pi_offset;
    start_tx * (constants.AVM_PUBLIC_INPUTS_GAS_SETTINGS_GAS_LIMITS_ROW_IDX - gas_limit_pi_offset) = 0;
    is_teardown_phase * (constants.AVM_PUBLIC_INPUTS_GAS_SETTINGS_TEARDOWN_GAS_LIMITS_ROW_IDX - gas_limit_pi_offset) = 0;

    // Gas limit is read twice, but not on start and end, but rather on start and teardown.
    // On start we read the general tx gas limit, and on teardown we read the teardown gas limit.
    pol commit should_read_gas_limit;
    should_read_gas_limit = start_tx + is_teardown_phase;

    #[PUBLIC_INPUTS_READ_GAS_LIMIT]
    should_read_gas_limit {
        gas_limit_pi_offset,
        da_gas_limit,
        l2_gas_limit
    } in public_inputs.sel {
        precomputed.clk,
        public_inputs.cols[0],
        public_inputs.cols[1]
    };

    // Reset side effect states on start
    start_tx * prev_num_unencrypted_logs = 0;
    start_tx * prev_num_l2_to_l1_messages = 0;

    // Next Tree State
    pol commit next_note_hash_tree_root;
    pol commit next_note_hash_tree_size;
    pol commit next_num_note_hashes_emitted;

    pol commit next_nullifier_tree_root;
    pol commit next_nullifier_tree_size;
    pol commit next_num_nullifiers_emitted;

    pol commit next_public_data_tree_root;
    pol commit next_public_data_tree_size;

    pol commit next_written_public_data_slots_tree_root;
    pol commit next_written_public_data_slots_tree_size;

    pol commit next_retrieved_bytecodes_tree_root;
    pol commit next_retrieved_bytecodes_tree_size;

    // Gas Info
    pol commit next_l2_gas_used;
    pol commit next_da_gas_used;

    // Next side effect states
    pol commit next_num_unencrypted_logs;
    pol commit next_num_l2_to_l1_messages;

    pol NOT_LAST_ROW = sel * sel';

    // Base continuity constraints
    #[NOTE_HASH_ROOT_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_note_hash_tree_root - prev_note_hash_tree_root') = 0;
    #[NOTE_HASH_TREE_SIZE_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_note_hash_tree_size - prev_note_hash_tree_size') = 0;
    #[NUM_NOTE_HASHES_EMITTED_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_num_note_hashes_emitted - prev_num_note_hashes_emitted') = 0;
    #[NULLIFIER_TREE_ROOT_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_nullifier_tree_root - prev_nullifier_tree_root') = 0;
    #[NULLIFIER_TREE_SIZE_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_nullifier_tree_size - prev_nullifier_tree_size') = 0;
    #[NUM_NULLIFIERS_EMITTED_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_num_nullifiers_emitted - prev_num_nullifiers_emitted') = 0;
    #[PUBLIC_DATA_TREE_ROOT_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_public_data_tree_root - prev_public_data_tree_root') = 0;
    #[PUBLIC_DATA_TREE_SIZE_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_public_data_tree_size - prev_public_data_tree_size') = 0;
    #[WRITTEN_PUBLIC_DATA_SLOTS_TREE_ROOT_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_written_public_data_slots_tree_root - prev_written_public_data_slots_tree_root') = 0;
    #[WRITTEN_PUBLIC_DATA_SLOTS_TREE_SIZE_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_written_public_data_slots_tree_size - prev_written_public_data_slots_tree_size') = 0;
    #[L1_L2_TREE_ROOT_CONTINUITY]
    NOT_LAST_ROW * (l1_l2_tree_root - l1_l2_tree_root') = 0;
    #[RETRIEVED_BYTECODES_TREE_ROOT_CONTINUITY]
    NOT_LAST_ROW * (next_retrieved_bytecodes_tree_root - prev_retrieved_bytecodes_tree_root') = 0;
    #[RETRIEVED_BYTECODES_TREE_SIZE_CONTINUITY]
    NOT_LAST_ROW * (next_retrieved_bytecodes_tree_size - prev_retrieved_bytecodes_tree_size') = 0;

    #[NUM_UNENCRYPTED_LOGS_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_num_unencrypted_logs - prev_num_unencrypted_logs') = 0;
    #[NUM_L2_TO_L1_MESSAGES_CONTINUITY]
    NOT_LAST_ROW * (1 - reverted) * (next_num_l2_to_l1_messages - prev_num_l2_to_l1_messages') = 0;

    pol commit setup_phase_value;
    sel * (4 - setup_phase_value) = 0;

    #[RESTORE_STATE_ON_REVERT]
    reverted {
        setup_phase_value,
        reverted, // end_phase = 1
        prev_note_hash_tree_root',
        prev_note_hash_tree_size',
        prev_num_note_hashes_emitted',
        prev_nullifier_tree_root',
        prev_nullifier_tree_size',
        prev_num_nullifiers_emitted',
        prev_public_data_tree_root',
        prev_public_data_tree_size',
        prev_written_public_data_slots_tree_root',
        prev_written_public_data_slots_tree_size',
        prev_num_unencrypted_logs',
        prev_num_l2_to_l1_messages'
    } in
    tx.sel {
        phase_value,
        end_phase,
        next_note_hash_tree_root,
        next_note_hash_tree_size,
        next_num_note_hashes_emitted,
        next_nullifier_tree_root,
        next_nullifier_tree_size,
        next_num_nullifiers_emitted,
        next_public_data_tree_root,
        next_public_data_tree_size,
        next_written_public_data_slots_tree_root,
        next_written_public_data_slots_tree_size,
        next_num_unencrypted_logs,
        next_num_l2_to_l1_messages
    };

    #[PROPAGATE_L2_GAS_USED]
    NOT_LAST_ROW * (next_l2_gas_used - prev_l2_gas_used') = 0;
    #[PROPAGATE_DA_GAS_USED]
    NOT_LAST_ROW * (next_da_gas_used - prev_da_gas_used') = 0;

    #[PROPAGATE_L2_GAS_LIMIT]
    NOT_LAST_ROW * (1 - is_teardown_phase') * (l2_gas_limit - l2_gas_limit') = 0;
    #[PROPAGATE_DA_GAS_LIMIT]
    NOT_LAST_ROW * (1 - is_teardown_phase') * (da_gas_limit - da_gas_limit') = 0;

    // Selectors to allow prev => next state changes on the different phases
    pol commit sel_can_emit_note_hash;
    pol commit sel_can_emit_nullifier;
    pol commit sel_can_write_public_data;
    pol commit sel_can_emit_unencrypted_log;
    pol commit sel_can_emit_l2_l1_msg;


    #[NOTE_HASH_ROOT_IMMUTABILITY]
    sel * (1 - sel_can_emit_note_hash) * (prev_note_hash_tree_root - next_note_hash_tree_root) = 0;
    #[NOTE_HASH_SIZE_IMMUTABILITY]
    sel * (1 - sel_can_emit_note_hash) * (prev_note_hash_tree_size - next_note_hash_tree_size) = 0;
    #[NOTE_HASH_COUNT_IMMUTABILITY]
    sel * (1 - sel_can_emit_note_hash) * (prev_num_note_hashes_emitted - next_num_note_hashes_emitted) = 0;

    #[NULLIFIER_ROOT_IMMUTABILITY]
    sel * (1 - sel_can_emit_nullifier) * (prev_nullifier_tree_root - next_nullifier_tree_root) = 0;
    #[NULLIFIER_SIZE_IMMUTABILITY]
    sel * (1 - sel_can_emit_nullifier) * (prev_nullifier_tree_size - next_nullifier_tree_size) = 0;
    #[NULLIFIER_COUNT_IMMUTABILITY]
    sel * (1 - sel_can_emit_nullifier) * (prev_num_nullifiers_emitted - next_num_nullifiers_emitted) = 0;

    #[PUBLIC_DATA_ROOT_IMMUTABILITY]
    sel * (1 - sel_can_write_public_data) * (prev_public_data_tree_root - next_public_data_tree_root) = 0;
    #[PUBLIC_DATA_SIZE_IMMUTABILITY]
    sel * (1 - sel_can_write_public_data) * (prev_public_data_tree_size - next_public_data_tree_size) = 0;
    #[WRITTEN_PUBLIC_DATA_SLOTS_ROOT_IMMUTABILITY]
    sel * (1 - sel_can_write_public_data) * (prev_written_public_data_slots_tree_root - next_written_public_data_slots_tree_root) = 0;
    #[WRITTEN_PUBLIC_DATA_SLOTS_SIZE_IMMUTABILITY]
    sel * (1 - sel_can_write_public_data) * (prev_written_public_data_slots_tree_size - next_written_public_data_slots_tree_size) = 0;

    #[UNENCRYPTED_LOG_COUNT_IMMUTABILITY]
    sel * (1 - sel_can_emit_unencrypted_log) * (prev_num_unencrypted_logs - next_num_unencrypted_logs) = 0;

    #[L2_TO_L1_MESSAGE_COUNT_IMMUTABILITY]
    sel * (1 - sel_can_emit_l2_l1_msg) * (prev_num_l2_to_l1_messages - next_num_l2_to_l1_messages) = 0;

    #[RETRIEVED_BYTECODES_TREE_ROOT_IMMUTABILITY]
    sel * (1 - should_process_call_request) * (prev_retrieved_bytecodes_tree_root - next_retrieved_bytecodes_tree_root) = 0;
    #[RETRIEVED_BYTECODES_TREE_SIZE_IMMUTABILITY]
    sel * (1 - should_process_call_request) * (prev_retrieved_bytecodes_tree_size - next_retrieved_bytecodes_tree_size) = 0;

    // Padded rows are not allowed to change the state
    #[NOTE_HASH_ROOT_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_note_hash_tree_root - next_note_hash_tree_root) = 0;
    #[NOTE_HASH_SIZE_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_note_hash_tree_size - next_note_hash_tree_size) = 0;
    #[NOTE_HASH_COUNT_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_num_note_hashes_emitted - next_num_note_hashes_emitted) = 0;

    #[NULLIFIER_ROOT_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_nullifier_tree_root - next_nullifier_tree_root) = 0;
    #[NULLIFIER_SIZE_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_nullifier_tree_size - next_nullifier_tree_size) = 0;
    #[NULLIFIER_COUNT_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_num_nullifiers_emitted - next_num_nullifiers_emitted) = 0;

    #[PUBLIC_DATA_ROOT_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_public_data_tree_root - next_public_data_tree_root) = 0;
    #[PUBLIC_DATA_SIZE_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_public_data_tree_size - next_public_data_tree_size) = 0;
    #[WRITTEN_PUBLIC_DATA_SLOTS_ROOT_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_written_public_data_slots_tree_root - next_written_public_data_slots_tree_root) = 0;
    #[WRITTEN_PUBLIC_DATA_SLOTS_SIZE_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_written_public_data_slots_tree_size - next_written_public_data_slots_tree_size) = 0;

    // The retrieved bytecodes tree is already immutable except for nonpadded call request rows

    #[UNENCRYPTED_LOG_COUNT_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_num_unencrypted_logs - next_num_unencrypted_logs) = 0;
    #[L2_TO_L1_MESSAGE_COUNT_PADDED_IMMUTABILITY]
    sel * is_padded * (prev_num_l2_to_l1_messages - next_num_l2_to_l1_messages) = 0;

    #[L2_GAS_USED_IMMUTABILITY]
    sel * (1 - should_process_call_request) * (prev_l2_gas_used - next_l2_gas_used) = 0;
    #[DA_GAS_USED_IMMUTABILITY]
    sel * (1 - should_process_call_request) * (prev_da_gas_used - next_da_gas_used) = 0;

    // Write end counters to PI

    // Write note hash count to PI
    pol commit array_length_note_hashes_pi_offset;

    is_cleanup * (constants.AVM_PUBLIC_INPUTS_AVM_ACCUMULATED_DATA_ARRAY_LENGTHS_NOTE_HASHES_ROW_IDX - array_length_note_hashes_pi_offset) = 0;

    #[PUBLIC_INPUTS_WRITE_NOTE_HASH_COUNT]
    is_cleanup {
        array_length_note_hashes_pi_offset,
        prev_num_note_hashes_emitted
    } in public_inputs.sel {
        precomputed.clk,
        public_inputs.cols[0]
    };

    // Write nullifier count to PI
    pol commit array_length_nullifiers_pi_offset;

    is_cleanup * (constants.AVM_PUBLIC_INPUTS_AVM_ACCUMULATED_DATA_ARRAY_LENGTHS_NULLIFIERS_ROW_IDX - array_length_nullifiers_pi_offset) = 0;

    #[PUBLIC_INPUTS_WRITE_NULLIFIER_COUNT]
    is_cleanup {
        array_length_nullifiers_pi_offset,
        prev_num_nullifiers_emitted
    } in public_inputs.sel {
        precomputed.clk,
        public_inputs.cols[0]
    };

    // Public data write counter is handled by the public data check trace due to squashing.

    // Write l2 to l1 message count to PI
    pol commit array_length_l2_to_l1_messages_pi_offset;

    is_cleanup * (constants.AVM_PUBLIC_INPUTS_AVM_ACCUMULATED_DATA_ARRAY_LENGTHS_L2_TO_L1_MSGS_ROW_IDX - array_length_l2_to_l1_messages_pi_offset) = 0;

    #[PUBLIC_INPUTS_WRITE_L2_TO_L1_MESSAGE_COUNT]
    is_cleanup {
        array_length_l2_to_l1_messages_pi_offset,
        prev_num_l2_to_l1_messages
    } in public_inputs.sel {
        precomputed.clk,
        public_inputs.cols[0]
    };

    // Write unencrypted log count to PI
    pol commit array_length_unencrypted_logs_pi_offset;

    is_cleanup * (constants.AVM_PUBLIC_INPUTS_AVM_ACCUMULATED_DATA_ARRAY_LENGTHS_PUBLIC_LOGS_ROW_IDX - array_length_unencrypted_logs_pi_offset) = 0;

    #[PUBLIC_INPUTS_WRITE_UNENCRYPTED_LOG_COUNT]
    is_cleanup {
        array_length_unencrypted_logs_pi_offset,
        prev_num_unencrypted_logs
    } in public_inputs.sel {
        precomputed.clk,
        public_inputs.cols[0]
    };

    // ===== EXECUTION CONTEXT ID =====

    // The next available context id. When peforming an enqueued call, this is the context id used by it.
    pol commit next_context_id;
    // Initial next context id is 1
    #[NEXT_CONTEXT_ID_INITIAL_VALUE]
    start_tx * (1 - next_context_id) = 0;

    // We normally propagate the next context id, unless a call is issued, where the execution trace
    // controls the next row's next context id.
    #[NEXT_CONTEXT_ID_CONTINUITY]
    NOT_LAST * (1 - should_process_call_request) * (next_context_id' - next_context_id) = 0;
