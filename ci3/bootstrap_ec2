#!/bin/bash
NO_CD=1 source $(git rev-parse --show-toplevel)/ci3/source
source $ci3/source_refname

cmd=${1:-"./bootstrap.sh ci"}
arch=${ARCH:-amd64}
NO_TERMINATE=${NO_TERMINATE:-0}

if [ "$arch" == "arm64" ]; then
  cores=64
  # Allow for 90 minutes as ARM has less cores.
  export AWS_SHUTDOWN_TIME=90
else
  if [ "$CI_FULL" -eq 1 ]; then
    cores=192
  else
    cores=128
  fi
fi

# Trap function to terminate our running instance when the script exits.
function on_exit {
    set +e
    if [ "$NO_TERMINATE" -eq 0 ]; then
      aws_terminate_instance $iid $sir
    else
      echo "Remote machine not terminated, connect with: ARCH=$arch ./ci.sh shell"
    fi
}

# Verify that the commit exists on the remote. It will be the remote tip of itself if so.
current_commit=$(git rev-parse HEAD)
if [[ "$(git fetch origin --negotiate-only --negotiation-tip=$current_commit)" != *"$current_commit"* ]]; then
  echo "Commit $current_commit is not pushed, exiting."
  exit 1
fi

if [ "$REF_NAME" == "master" ]; then
  # Allow parallelism on master by having the instance name be the commit.
  instance_name="$current_commit"_$arch
else
  instance_name=$(echo -n "$REF_NAME" | tr -c 'a-zA-Z0-9-' '_')_$arch
fi

[ -n "${INSTANCE_POSTFIX:-}" ] && instance_name+="_$INSTANCE_POSTFIX"

echo_header "request build instance"
# Terminate any existing instance with the same name.
existing_instance=$(aws ec2 describe-instances \
  --region us-east-2 \
  --filters "Name=tag:Name,Values=$instance_name" \
  --query "Reservations[].Instances[?State.Name!='terminated'].InstanceId[]" \
  --output text)
if [ -n "$existing_instance" ]; then
  echo "Terminating existing instance: $existing_instance"
  aws ec2 --region us-east-2 terminate-instances --instance-ids $existing_instance > /dev/null 2>&1
fi

# Request new instance.
ip_sir=$(aws_request_instance $instance_name $cores $arch)
IFS=':' read -r -a parts <<< "$ip_sir"
ip="${parts[0]}"
sir="${parts[1]}"
iid="${parts[2]}"
trap on_exit EXIT

# If we're asking to not terminate the instance automatically, we also don't want to remove the container.
[ "$NO_TERMINATE" -eq 0 ] && docker_args+=" --rm"

# Interactive if stdin is connected to terminal.
[ -t 0 ] && docker_args+=" -i"

# If stdout is connected to a terminal, drop into a shell on failure.
# Otherwise ensure all logs go to redis cache.
if [ -t 1 ]; then
  ssh_args="-t"
  docker_args+=" -t"
  if [ "$NO_TERMINATE" -eq 0 ]; then
    cmd+=" || exec zsh"
  else
    cmd+="; exec zsh"
  fi
else
  # LOG_ID can optionally be set externally to be e.g. the GA run id.
  cmd="ci3/aws_handle_evict '$cmd' 2>&1 | ci3/add_timestamps | ci3/cache_log 'CI run' ${LOG_ID:-}"
fi

container_script=$(cat <<EOF
  set -euo pipefail
  # When restarting the container, just hang around.
  while [ -f started ]; do sleep 999; done
  touch started
  sudo chown aztec-dev:aztec-dev aztec-packages
  cd aztec-packages
  git config --global advice.detachedHead false
  git init . &>/dev/null
  git remote add origin https://github.com/aztecprotocol/aztec-packages
  git fetch --depth 1 origin $current_commit
  git checkout FETCH_HEAD
  git checkout -b $REF_NAME
  export CI_FULL=$CI_FULL
  source ci3/source
  echo "env: REF_NAME=$REF_NAME COMMIT_HASH=$COMMIT_HASH CURRENT_VERSION=$CURRENT_VERSION CI_FULL=$CI_FULL"
  if semver check "$REF_NAME"; then
    echo "Performing a release because $REF_NAME is a semver."
  fi
  set -x
  $cmd
EOF
)

# Use ~/.ssh/build_instance_key to ssh into our requested instance.
# Launch our devbox container, clones the branches latest commit and runs the given command.
# To improve performance we:
#   - Use a volume on /var/lib/docker for docker-in-docker as overlayfs trashes performance (in fact it just breaks).
#   - The volume has the devbox image preloaded within it in the ami_update.sh script.
#   - Use a volume for the actual working directory in /home/aztec-dev/aztec-packages.
#   - Copy the CRS into a 3G tmpfs and mount that into the container.
#   - Mount the hosts /tmp into the container.
# We mount in aws credentials to leverage the s3 cache.
# We enable the test cache, which uses a redis instance for tracking test runs.
# We set SSH_CONNECTION to something to ensure the hostname is shown in the lean prompt.
# We provide the host user and group ids to the entrypoint script to ensure alignment.
# We raise the default pid limit to 32k.
set +e
ssh ${ssh_args:-} -F $ci3/aws/build_instance_ssh_config ubuntu@$ip "
  # TODO: This should *not* be needed in a CI run. Remove "watching" code, e.g. in boxes.
  sudo sysctl fs.inotify.max_user_watches=1048576 &>/dev/null
  sudo sysctl fs.inotify.max_user_instances=1048576 &>/dev/null

  echo Loading CRS into tmpfs...
  sudo mkdir /mnt/bb-crs
  sudo mount -t tmpfs -o size=3G tmpfs /mnt/bb-crs
  sudo cp -r \$HOME/.bb-crs/* /mnt/bb-crs
  echo Done in \$SECONDS seconds.

  echo Starting devbox...
  docker run --privileged ${docker_args:-} \
    --name aztec_build \
    --hostname $instance_name \
    -v bootstrap_ci_local_docker:/var/lib/docker \
    -v bootstrap_ci_repo:/home/aztec-dev/aztec-packages \
    -v \$HOME/.aws:/home/aztec-dev/.aws:ro \
    -v /mnt/bb-crs:/home/aztec-dev/.bb-crs:ro \
    -v /tmp:/tmp \
    -e USE_TEST_CACHE=1 \
    -e CI_REDIS='ci-redis.lzka0i.0001.use2.cache.amazonaws.com' \
    -e SSH_CONNECTION=' ' \
    -e LOCAL_USER_ID=\$(id -u) \
    -e LOCAL_GROUP_ID=\$(id -g) \
    -e BUILD_SYSTEM_DEBUG=${BUILD_SYSTEM_DEBUG:-} \
    -e GITHUB_TOKEN=${GITHUB_TOKEN:-} \
    -e NETLIFY_SITE_ID=${NETLIFY_SITE_ID:-} \
    -e NETLIFY_AUTH_TOKEN=${NETLIFY_AUTH_TOKEN:-} \
    --pids-limit=32768 \
    aztecprotocol/devbox:3.0 bash -c $(printf '%q' "$container_script")
"
code=$?
set -e
echo "SSH exited with code: $code"

# If we were spot evicted, try again using on-demand.
if [ $code -eq 155 ]; then
  echo "Spot was evicted. Retrying with on-demand instance."
  NO_SPOT=1 exec "$0" "$@"
else
  exit $code
fi
